# 0.面向对象设计7大原则

1. 开闭原则：对扩展开放，对修改关闭。核心思想是面向接口/抽象进行编程
2. 里式替换原则：可以用子类来替代父类
3. 依赖倒转原则：依赖抽象（接口/抽象类）而不是具体的实现（实现类）进行编程
4. 单一职责原则：一个类只实现单一或独立的业务功能
5. 接口隔离原则：一个类应该依赖尽量少的接口，减少冗余性和复杂性。
6. 组合/聚合复用原则：尽量使用组合/聚合而不是继承
7. 迪米特原则：设计对象时，使其尽可能少地依赖其他对象，降低耦合度。

# 1. JAVA基础

## 1.1 基本数据类型

| 基本数据类型 | 大小（字节） | 默认值          |
| :----------: | ------------ | --------------- |
|     byte     | 1            | 0               |
|    short     | 2            | 0               |
|     int      | 4            | 0               |
|     long     | 8            | 0L              |
|    float     | 4            | 0.0f            |
|    double    | 8            | 0.0d            |
|   boolean    | \            | false           |
|     char     | 2            | '\u0000‘ 空字符 |

6种数字类型（整型、浮点型），1种字符类型 ，1种布尔类型。

## 1.2 int和Integer的区别

|      int       |   Integer    |
| :------------: | :----------: |
|  基本数据类型  | int的包装类  |
|  不需要实例化  |  必须实例化  |
| 直接存储数据值 | 对对象的引用 |
|    默认值0     |  默认值null  |

讲一下这两句代码后面的运行过程

```java
Integer i = 10;
Integer i = 128;
```

都调用了Integer类的静态方法valueOf。

该静态方法首先会对传入的数x进行大小判断，若位于-128~127的范围里，则直接从cache中获取，值相同，地址相同；若不在此范围，则new Integer(x)，值相同，地址不相同。故，

```java
Integer i = 128;
Integer j = 128;
System.out.print(i == j); //false
Integer i = 100;
Integer j = 100;
System.out.print(i == j); //true
```

### 1.2.1 Integer.valueOf和Integer.parseInt区别

前者返回一个Integer对象，后者返回int基础类型。

### 1.2.2 intValue()方法

1.intValue()是**java.lang.Number类的方法**，**Number是一个抽象类。Java中所有的数值类都继承它**。也就是说，不单是Integer有intValue方法，Double，Long等都有此方法。 
2.此方法的意思是：**输出int数据**。每个数值类中具体的实现是不同的。例如： 
Float类和Double类的intValue方法，就是丢掉了小数位，而Long的intValue方法又不一样的

### 1.2.3 intValue和parseInt的区别

虽然都是返回int基础类型，但前者是实例方法，后者是静态方法。

## 1.3 final、 static 、this、super关键字

### final

**1. 数据**

声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。

- 对于基本类型，final 使数值不变；
- 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。

```java
final int x = 1;
// x = 2;  // cannot assign value to final variable 'x'
final A y = new A();
y.a = 1;
```

**2. 方法**

声明方法不能被子类重写。

private 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。

**3. 类**

声明类不允许被继承。

### static

**1. 静态变量**

- 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。
- 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。

```java
public class A {

    private int x;         // 实例变量
    private static int y;  // 静态变量

    public static void main(String[] args) {
        // int x = A.x;  // Non-static field 'x' cannot be referenced from a static context
        A a = new A();
        int x = a.x;
        int y = A.y;
    }
}
```

**2. 静态方法**

静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。

```java
public abstract class A {
    public static void func1(){
    }
    // public abstract static void func2();  // Illegal combination of modifiers: 'abstract' and 'static'
}
```

只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字，因此这两个关键字与具体对象关联。

```java
public class A {

    private static int x;
    private int y;

    public static void func1(){
        int a = x;
        // int b = y;  // Non-static field 'y' cannot be referenced from a static context
        // int b = this.y;     // 'A.this' cannot be referenced from a static context
    }
}
```

**3. 静态语句块**

静态语句块在类初始化时运行一次。

```java
public class A {
    static {
        System.out.println("123");
    }

    public static void main(String[] args) {
        A a1 = new A();
        A a2 = new A();
    }
}
123
```

**4. 静态内部类**

非静态内部类依赖于外部类的实例，也就是说需要先创建外部类实例，才能用这个实例去创建非静态内部类。而静态内部类不需要。

```java
public class OuterClass {

    class InnerClass {
    }

    static class StaticInnerClass {
    }

    public static void main(String[] args) {
        // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context
        OuterClass outerClass = new OuterClass();
        InnerClass innerClass = outerClass.new InnerClass();
        StaticInnerClass staticInnerClass = new StaticInnerClass();
    }
}
```

静态内部类不能访问外部类的非静态的变量和方法。

**5. 静态导包**

在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。

```java
import static com.xxx.ClassName.*
```

**6. 初始化顺序**

静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。

```java
public static String staticField = "静态变量";
static {
    System.out.println("静态语句块");
}
public String field = "实例变量";
{
    System.out.println("普通语句块");
}
```

最后才是构造函数的初始化。

```java
public InitialOrderTest() {
    System.out.println("构造函数");
}
```

存在继承的情况下，初始化顺序为：

- 父类（静态变量、静态语句块）
- 子类（静态变量、静态语句块）
- 父类（实例变量、普通语句块）
- 父类（构造函数）
- 子类（实例变量、普通语句块）
- 子类（构造函数）

### super

- 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。应该注意到，子类一定会调用父类的构造函数来完成初始化工作，一般是调用父类的默认构造函数，如果子类需要调用父类其它构造函数，那么就可以使用 super() 函数。
- 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。

### this

- 访问本类的构造函数
- 访问本类的成员

## 1.4 final，finalize， finally的区别

final：关键字，修饰数据、方法、类。

finalize：当一个对象因GC Roots不可达被标记后，若其重写过finalize方法并且之前未执行过，则会执行该方法。该对象会被放入一个队列中进行第二次标记，若与引用链上的任何对象建立了关联，则复活，否则才会被真正回收。

finally：与try catch联合使用，1、无论异常是否被捕获，都会执行finally中的代码 2、finally里适合存放释放资源、后续处理的代码。（不执行finally的情况：1、finally第一行发生异常 2、异常语句前调用了System.exit()退出程序   3、程序所在线程死亡   4、CPU关闭）

## 1.5 String、Stringbuffer和StringBuilder的区别

String：低层是被final修饰的byte数组，**不可变**、**线程安全**。

StringBuffer：线程安全，使用synchronized进行同步。

StringBuilder：线程不安全

### 1.5.1 String相关

![image-20200723132342460](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200723132342460.png)

xxx.intern()作用：首先查询常量池中是否存在，有，返回常量池中的引用，否，将xxx在堆中的地址放入并返回该地址。

<img src="C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20201013215429030.png" alt="image-20201013215429030"  />

Class常量池：class文件中

运行时常量池：元空间

字符串常量池：堆

## 1.6 Equals方法重写时为什么要重写hashcode方法？

先验知识：hashCode() 返回哈希值，而 equals() 是用来判断两个对象是否等价。

重写的目的是保证等价的两个对象哈希值也相等。

## 1.7 ==和equals的区别

对于基本数据类型：==判断**值**是否相等， 没有equals方法

对于引用类型：==判断**地址**是否想等，若重写了equals方法，判断对象是否**等价**；未重写，判断**地址**。

## 1.8 接口与抽象类的区别

1. 接口中只能有**public** **static、final** 变量，而抽象类中则不一定。
2. 一个类可以实现多个接口，但只能继承一个抽象类。接口自己本身可以通过 extends 关键字扩展多个接口。
3. 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。

总结一下 jdk7~jdk9 Java 中接口概念的变化：

1. 在 jdk 7 或更早版本中，接口里面只能有常量变量和抽象方法。这些接口方法必须由选择实现接口的类实现。
2. jdk8 的时候接口可以有默认方法和静态方法功能。（为何引入默认方法？以免接口中增加新的抽象方法后，每个接口实现类都要实现该方法。 为何引入静态方法？不用实例化，直接使用，节省内存空间）
3. Jdk 9 在接口中引入了私有方法和私有静态方法。（为何引入私有方法？解决多个默认方法之间重复代码的问题。 为何引入私有静态？解决多个静态方法之间的重复代码问题）

## 1.9 Java中泛型

将类型参数化，提供了**编译期**（只在编译期有效）的类型安全，确保你只能把正确类型的对象放入集合中，避免了在运行时出现ClassCastException。

工作机制：通过**类型擦除**实现，在编译阶段，所有泛型类的类型参数都会被Object或者它们的限定边界来替换。可以用**反射机制**获取泛型类型。

## 1.10 Java多态

口诀：“**成员变量、静态方法**：看左边；                 **非静态方法**：编译看左边，运行看右边。“ 意思是：当父类变量引用子类对象时，在这个引用变量f指向的对象中，他的成员变量和静态方法与父类是一致的，他的非静态方法，在编译时是与父类一致的，运行时却与子类一致（发生了重写）



分为编译时多态和运行时多态

### 编译时多态

也就是所谓的方法重载，根据参数，选择执行不同的方法体

### 运行时多态

一个**引用变量**到底会指向**哪个类的实例对象**，该**引用变量发出的方法调用**到底是**哪个类中实现的方法**，必须在由程序**运行期间**才能决定。

两种形式：父类引用指向子类对象or接口引用指向实现类对象。

作用：增强代码可扩展性。

#### JAVA多态实现原理

##### Java的方法调用方式

Java 的方法调用有两类，**动态方法调用**与**静态方法调用**。静态方法调用是指对于类的静态方法的调用方式，是静态绑定的；而动态方法调用需要有方法调用所作用的对象，是动态绑定的。**类调用** (invokestatic) 是在**编译**时刻就已经确定好具体调用方法的情况，而**实例调用** (invokevirtual) 则是在**调用**的时候才确定具体的调用方法，这就是**动态绑定，是多态要解决的核心问题**。 

Java 对于 方法调用 动态绑定 的实现依靠**方法表**。当某个方法被调用时，JVM 首先要查找相应的**常量池**，得到方法的**符号引用**，并**查找调用类的方法表**以确定该方法的**直接引用**，最后才真正调用该方法。

## 1.11 JDK 、JRE、JVM

JDK：Java development kit，用于**创建、编译**程序，包含JRE、编译器（javac）和工具（如 javadoc 和 jdb）

JRE：Java running environment， 用于**运行**已编译的程序，包含了运行已编译程序所需的所有内容，比如JVM、类库等。

## 1.12 重写和重载区别

| 区别点     | 重载方法 | 重写方法                                       |
| ---------- | -------- | ---------------------------------------------- |
| 发生范围   | 同一个类 | 子类 中                                        |
| 参数列表   | 必须修改 | 一定不能修改                                   |
| 返回类型   | 可修改   | 小于等于父类方法的返回类型                     |
| 异常       | 可修改   | 可以减少或删除，一定不能抛出新的或者更广的异常 |
| 访问修饰符 | 可修改   | 一定不能做更严格的限制（可以降低限制）         |
| 发生阶段   | 编译期   | 运行期                                         |

重载实际上是使用静态分派的，重载时是通过参数的静态类型而不是实际类型作为判定依据的。详细参考深入理解java虚拟机248页解释。（如 Human a = new Man(), Human是静态类型， Man是实际类型）

## 1.13 封装、继承、多态

封装：私有化类的属性，向外提供方法函数对其进行访问。

继承：在旧类的基础上进行扩展，创建新类，增加新的属性或功能。继承的好处：复用代码。

​	1、子类拥有父类所有的属性和方法，其中私有属性和私有方法不能访问

​	2、子类可以拥有自己的属性和方法，即进行扩展

​	3、子类可对父类方法进行重写

多态：引用变量指向的类型、通过该变量发出的方法调用中方法属于哪个类，只能在运行期确定。

## 1.14 Java访问修饰符

![image-20201204143427686](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20201204143427686.png)

![image-20201204143453076](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20201204143453076.png)

## 1.15 内存泄漏

**内存泄漏**：申请内存后，无法释放已申请的内存空间。  **内存溢出**：申请内存时，没有足够的内存空间可供使用。

内存泄漏的情况 ：

1、静态集合类中存放对象。即长生命周期的对象持有短生命周期对象的引用，导致短生命周期对象无法回收。

2、数据库连接、网络连接、IO连接时，资源未关闭造成的内存泄漏。如使用数据库时，只有关闭ResultSet、Statement、Connection后，垃圾收集器才会回收相应得对象。

3、内部类持有外部类的实例对象。

4、变量的作用域不合理。一般而言，一个变量的定义的作用范围大于其使用范围，很有可能会造成内存泄漏。另一方面，如果没有及时地把对象设置为null，很有可能导致内存泄漏的发生。

5、改变哈希值。当一个对象放入HashSet集合后，改变该对象的哈希值，会导致该对象无法被检索到，也导致无法主动删除该对象，造成内存泄漏。

6、ThreadLocalMap中存在的内存泄漏问题。key为ThreadLocal的弱引用，value为强引用。GC时，key被回收，变为null，进而导致value无法被查找到，造成内存泄漏。

## 1.18 受检异常和非受检异常

受检：强制要求调用者处理的异常，IOException

非受检：指不强制要求调用者处理的异常，包括RuntimeException和Error。

### 1.18.1 RuntimeException（非受检异常）有哪些

越界、空指针、算术、classCastException、missingResource、illegalArgument、unknownType。

### 1.18.2如何避免空指针异常

1、调用已知String对象的equals方法，而非未知对象(因为这样会引起空指针异常)

2、使用String.valueOf()而非toString()，因为当对象为空时后者会抛异常，前者会返回“null"字符串。

3、使用空指针安全的方法和库，比如StringUtils.isBlank()、isNumeric()

4、避免从方法中返回空指针，而是返回空集合或者空数组。Collention类提供了空List,Set,Map, Collections.EMPTY_LIST, EMPTY_SET, EMPTY_MAP

5、使用注解如@NotNull   @Nullable。使用反射的方式进行空指针检查，[如](https://blog.csdn.net/chen213wb/article/details/88013128)![image-20201210161651187](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20201210161651600.png)

6、避免代码中不必要的自动装箱和拆箱。如果包装对象是null，拆箱时会有空指针异常。

7、定义数据库中的字段是否可为空，这可减少代码中的空指针检查。

## 1.19 反射

JAVA 反射机制是在运行状态中，能知道任何类的所有属性和方法；调用任何对象的属性和方法；这种动态获取的信息以及动态调用对象的方法的功能称为 java 语言的反射机制。

应用场景：

1. 我们在使用 JDBC 连接数据库时使用 `Class.forName()`通过反射加载数据库的驱动程序；
2. Spring 框架的 IOC（动态加载管理 Bean）创建对象以及 AOP（动态代理）功能都和反射有联系；
3. 动态配置实例的属性；

## 1.20 动态代理

#### **JDK Proxy**

需要被代理的对象实现了某个接口，然后把该接口的class文件传入newProxyInstance,这样才能知道要invoke的方法。比如tank实现了moveable接口，newProxyInstance接收到后，会生成一个moveable接口中的方法move, 在内部调用传入的InvocationHandler（对应代码中的h， h在$Proxy0的构造函数中被初始化）的invoke方法.其中的this指的就是生成的代理对象。![image-20200727151652819](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200727151652819.png)

代理的字节码文件：<img src="C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200727150516187.png" alt="image-20200727150516187" style="zoom:50%;" />

#### Cglib

![image-20200807091758049](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200807091758049.png)

<img src="C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200807094735628.png" alt="image-20200807094735628" style="zoom: 67%;" />

过程：tank.move() ->调用拦截器->methodProxy.invokeSuper->CGLIB$move$0(代理方法)->被代理对象的move方法

methodProxy.invokeSuper内部是 先获取到代理类对应的**FastClass**，然后执行代理方法。

**FastClass**机制：为代理类和被代理类各生成一个FastClass，FastClass会为各自的方法分配index(int类型)。通过index，可以直接定位要调用的方法并进行调用，这样省去了反射调用，所以调用效率比JDK动态代理通过反射调用高。 

FastClass是在第一次执行MethodProxy invokeSuper时生成并放入缓存的。



#### JDK 和 CGLIB区别

```
1.JDK动态代理是实现了被代理对象的接口，Cglib是继承了被代理对象。
2.JDK和Cglib都是在运行期生成字节码，JDK是直接写Class字节码，Cglib使用ASM框架写Class字节码，Cglib代理实现更复杂，生成代理类比JDK效率低。
3.JDK调用代理方法，是通过反射机制调用，Cglib是通过FastClass机制直接调用方法，Cglib执行效率更高。
```



## 1.21 注解

**定义**：Java注解是附加在代码中的一些元信息，用于一些工具在**编译、运行**时 进行 **解析和使用** ，起到**说明、配置**的功能。

**用处**：

1、生成文档 @param @return

2、跟踪代码依赖性，起到替代配置文件的功能。

3、编译时进行格式检查

**原理**：

　注解本质是一个继承了Annotation接口 的特殊接口，其具体实现类是Java 运行时生成的动态代理类。我们通过反射获取注解时，返回Java 运行时生成的动态代理对象$Proxy1。通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler 的invoke 方法。该方法会从memberValues 这个Map 中索引出对应的值。而memberValues 的来源是Java 常量池。



## 1.22 元注解

java.lang.annotation 提供了四种元注解，专门注解其他的注解（在自定义注解的时候，需要使用到元注解）：
  @Documented – 使用该元注解，注解的信息会被包含在JavaDoc中
  @Retention – 定义该注解的生命周期
  @Target – 定义该注解的作用位置
  @Inherited – 说明子类可以继承父类中的该注解

 1.）@Retention – 定义该注解的生命周期
 ●  RetentionPolicy.SOURCE : 只存在于**源代码**，编译时被忽略，不写入字节码文件。@Override, @SuppressWarnings，@Deprecated都属于这类注解。
 ●  RetentionPolicy.CLASS : 存在于**编译阶段**，在字节码文件中存在，但JVM会忽略。注解**默认**使用这种方式
 ●  RetentionPolicy.RUNTIME : 始终存在，运行期也保留该注解，因此可以使用**反射机制**读取该注解的信息。我们**自定义的注解**通常使用这种方式。

 2.）@Target – 定义该注解的作用位置。默认值为任何元素，表示该注解用于什么地方。可用的ElementType 参数包括
 ● ElementType.CONSTRUCTOR: 用于描述构造器
 ● ElementType.FIELD: 成员变量、对象、属性（包括enum实例）
 ● ElementType.LOCAL_VARIABLE: 用于描述局部变量
 ● ElementType.METHOD: 用于描述方法
 ● ElementType.PACKAGE: 用于描述包
 ● ElementType.PARAMETER: 用于描述参数
 ● ElementType.TYPE: 用于描述类、接口(包括注解类型) 或enum声明

 3.)@Documented – 一个简单的Annotations 标记注解，表示是否将注解信息添加在java 文档中。

 4.)@Inherited – 说明子类可以继承父类中的该注解
   @Inherited 元注解是一个标记注解，@Inherited 阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited 修饰的annotation 类型被用于一个class，则这个annotation 将被用于该class 的子类。

## 1.23 使用lambda表达式的优点

实现功能接口时减少使用单个类或匿名内部类，使代码更加简洁紧凑。

允许将函数作为方法的参数。

## 1.24 Arrays.sort()的JDK1.8实现

插入排序(数组长度<27) 归并排序(>286);

双轴快排（27<= len <=286）

具体过程：

1、用公式length/8+length/64+1近似计算出数组长度的1/7--seventh

2、找出中点，以数组长度的七分之一为间隔算出5个等间隔的索引

```java
 /*
     * Sort five evenly spaced elements around (and including) the
     * center element in the range. These elements will be used for
     * pivot selection as described below. The choice for spacing
     * these elements was empirically determined to work well on
     * a wide variety of inputs.
     */
    int e3 = (left + right) >>> 1; // The midpoint
    int e2 = e3 - seventh;
    int e1 = e2 - seventh;
    int e4 = e3 + seventh;
    int e5 = e4 + seventh;
```

3、对位于这五个索引位置上的元素进行插入排序，取第二和第四个元素分别作为轴pivot1和pivot2。

4、定义两个指针less和great，less从最左边开始向右遍历，一直找到第一个不小于pivot1的元素，great从右边开始向左遍历，一直找到第一个不大于pivot2的元素

5、接着定义指针k从less-1（注意会先++k）开始向右遍历至great，把小于pivot1的元素移动到less左边，大于pivot2的元素移动到great右边。这里要注意，我们已知great处的元素小于pivot2，但是它于pivot1的大小关系，还需要进行判断，如果比pivot1还小，需要移动到less左边、原先的位置放k处的元素，否则只需要和k处元素交换。

```java
/*
 * Partitioning:
 *
 *   left part           center part                   right part
 * +--------------------------------------------------------------+
 * |  < pivot1  |  pivot1 <= && <= pivot2  |    ?    |  > pivot2  |
 * +--------------------------------------------------------------+
 *               ^                          ^       ^
 *               |                          |       |
 *              less                        k     great
 *
 * Invariants:
 *
 *              all in (left, less)   < pivot1
 *    pivot1 <= all in [less, k)     <= pivot2
 *              all in (great, right) > pivot2
 *
 * Pointer k is the first index of ?-part.
 */
        outer:
        for (int k = less - 1; ++k <= great; ) {
            int ak = a[k];
            if (ak < pivot1) { // Move a[k] to left part
                a[k] = a[less];
                /*
                 * Here and below we use "a[i] = b; i++;" instead
                 * of "a[i++] = b;" due to performance issue.
                 */
                a[less] = ak;
                ++less;
            } else if (ak > pivot2) { // Move a[k] to right part
                while (a[great] > pivot2) {
                    if (great-- == k) {
                        break outer;
                    }
                }
                if (a[great] < pivot1) { // a[great] <= pivot2
                    a[k] = a[less];
                    a[less] = a[great];
                    ++less;
                } else { // pivot1 <= a[great] <= pivot2
                    a[k] = a[great];
                }
                /*
                 * Here and below we use "a[i] = b; i--;" instead
                 * of "a[i--] = b;" due to performance issue.
                 */
                a[great] = ak;
                --great;
            }
        }
```

6、将less-1处的元素移动到队头，great+1处的元素移动到队尾，并把pivot1和pivot2分别放到less-1和great+1处。

7、至此，less-1左边的元素都小于pivot1，great+1右边的元素都大于pivot2，分别对两部分进行同样的递归排序。

8、对于中间的部分，如果大于4/7的数组长度，很可能是因为重复元素的存在，所以把less向右移动到第一个不等于pivot1的地方，把great向左移动到第一个不等于pivot2的地方，然后再对less和great之间的部分进行递归排序。

## 1.25 Java8[的新特性](https://snailclimb.gitee.io/javaguide/#/docs/java/new-features/Java8%E6%96%B0%E7%89%B9%E6%80%A7%E6%80%BB%E7%BB%93?id=%e6%96%b9%e6%b3%95%e5%92%8c%e6%9e%84%e9%80%a0%e5%87%bd%e6%95%b0%e5%bc%95%e7%94%a8method-and-constructor-references)

1、接口中新添了默认方法和静态方法

2、lambda表达式：

3、函数式接口注解@FunctionalInterface：可使现有的函数友好地支持Lambda

4、方法和构造函数引用(Method and Constructor References)：Java 8允许您通过`::`关键字传递方法或构造函数的引用。

传递静态方法的引用：

```java
Converter<String, Integer> converter = Integer::valueOf;
    Integer converted = converter.convert("123");
    System.out.println(converted.getClass());   //class java.lang.Integer
```

传递普通方法的引用：

```java
class Something {
    String startsWith(String s) {
        return String.valueOf(s.charAt(0));
    }
}
Something something = new Something();
Converter<String, String> converter = something::startsWith;
String converted = converter.convert("Java");
System.out.println(converted);    // "J"
```

传递构造函数的引用：

```java
//先创建一个类
class Person {
    String firstName;
    String lastName;

    Person() {}

    Person(String firstName, String lastName) {
        this.firstName = firstName;
        this.lastName = lastName;
    }
}
//指定一个用来创建Person对象的对象工厂接口
interface PersonFactory<P extends Person> {
    P create(String firstName, String lastName);
}
//使用构造函数引用来将他们关联起来，而不是手动实现一个完整的工厂
PersonFactory<Person> personFactory = Person::new;
Person person = personFactory.create("Peter", "Parker");
//我们只需要使用 Person::new 来获取Person类构造函数的引用，Java编译器会自动根据PersonFactory.create方法的参数类型来选择合适的构造函数。
```

5、内置的函数式接口

JDK 1.8 API包含许多内置函数式接口。 其中一些借口在老版本的 Java 中是比较常见的比如： `Comparator` 或`Runnable`，这些接口都增加了`@FunctionalInterface`注解以便能用在 lambda 表达式上。新增的接口包括：Predicate

6、Stream流操作

表示能应用在一组元素上一次执行的操作序列。Stream 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回Stream本身，这样你就可以将多个操作依次串起来。Stream 的创建需要指定一个数据源，比如` java.util.Collection` 的子类，List 或者 Set， Map 不支持。Stream 的操作可以串行执行或者并行执行。

7、支持多重注解

Java 8允许我们把同一个类型的注解使用多次，只需要给该注解标注一下`@Repeatable`即可。

```java
//首先定义一个包装类Hints注解用来放置一组具体的Hint注解：
@interface Hints {
    Hint[] value();
}
@Repeatable(Hints.class)
@interface Hint {
    String value();
}
//使用包装类当容器来存多个注解（老方法）
@Hints({@Hint("hint1"), @Hint("hint2")})
class Person {}
//使用多重注解（新方法）
@Hint("hint1")
@Hint("hint2")
class Person {}
```

## 1.26 创建对象的几种方式

1、new出对象

2、使用反射机制，得到Class对象后调用Class.newInstance创建实例对象

3、调用对象的clone方法  （需要对象实现cloneable接口）

4、反序列化，ObjectInputStream对象的readObject方法

(前两种会调用构造函数，后两种不会)

## 1.27 Java IO的种类

#### BIO、NIO、AIO区别

BIO：同步阻塞IO模式，数据的读取、写入必须阻塞在一个线程内等待其完成；面向字节流。

NIO：同步非阻塞的IO模式，支持面向缓冲、基于通道的IO操作方法，实现了IO多路复用中的reactor模型，一个**线程**使用一个**选择器**通过**轮询**的方式去监听多个通道上的事件，从而让一个线程可以处理多个事件。

​		通过配置监听的通道为非阻塞，那么当通道上的IO事件还未到达时，就不会进入阻塞状态一直等待，而是会轮询其他channel，找到IO事件到达的channel执行。注意：只有套接字channel能配置成非阻塞。

AIO：异步非阻塞的IO模式，基于事件和回调机制，当用户线程发出调用请求后，可以继续做其他事，内核完成IO操作后，返回信号通知用户线程，进行后续操作。

## 1.28 Object类有哪些方法

1、getClass

2、hashCode()

3、equals

4、clone

5、toString

6、和线程通信相关的notify、notifyAll、wait

7、线程回收相关的finalize

# **2.JAVA容器**

## List、Set、Map区别

List:有序集合，允许元素重复，可放入多个null。ArrayList、LinkedList、Vector。

Set：不允许元素重复的集合，可放入一个null。

Map：存储键值对，key不能重复，value可以重复。

## ArrayList和LinkedList的区别



|                              | ArrayList                              | LinkedList                         |
| ---------------------------- | -------------------------------------- | ---------------------------------- |
| 线程安全                     | 非线程安全                             | 非线程安全                         |
| 低层数据结构                 | Object数组                             | 双向链表                           |
| 非首尾的插入和删除操作的效率 | 比LinkedList低，因为要影响其他数组元素 | 高                                 |
| 快速随机访问                 | 支持                                   | 不支持                             |
| 内存空间占用                 | 比LinkedList少                         | 每个元素要存放数据、直接前驱和后继 |

## ArrayList 扩容机制

```java
public void ensureCapacity(int minCapacity) {//该函数保障容量够用
    if (minCapacity > elementData.length
        && !(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA
             && minCapacity <= DEFAULT_CAPACITY)) {
        modCount++;
        grow(minCapacity);//核心的扩容函数
    }
}
```

```java
private Object[] grow(int minCapacity) {
    return elementData = Arrays.copyOf(elementData,
                                       newCapacity(minCapacity));
}
private int newCapacity(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        if (newCapacity - minCapacity <= 0) {
            if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA)
                return Math.max(DEFAULT_CAPACITY, minCapacity);
            if (minCapacity < 0) // overflow
                throw new OutOfMemoryError();
            return minCapacity;
        }
        return (newCapacity - MAX_ARRAY_SIZE <= 0)
            ? newCapacity
            : hugeCapacity(minCapacity);
    }

    private static int hugeCapacity(int minCapacity) {
        if (minCapacity < 0) // overflow
            throw new OutOfMemoryError();
        return (minCapacity > MAX_ARRAY_SIZE)
            ? Integer.MAX_VALUE
            : MAX_ARRAY_SIZE;
    }
```

## 为什么 ArrayList 的 elementData 加上 transient 修饰？

- ArrayList 中的数组定义如下：

  - private transient Object[] elementData;

- 再看一下 ArrayList 的定义：

  - public class ArrayList<E> extends AbstractList<E>

  - implements List<E>, RandomAccess, Cloneable, java.io.Serializable

- 可以看到 ArrayList 实现了 Serializable 接口，这意味着 ArrayList 支持序列化。transient 的作用是说不希望 elementData 数组被序列化，重写了 writeObject 实现：

  ```java
  private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{
  
  *// Write out element count, and any hidden stuff*
  
  int expectedModCount = modCount;
  
  s.defaultWriteObject();
  
   *// Write out 数组中元素的个数*   
  
   s.writeInt(size);
  
  *// Write out all elements in the proper order.*
  
   for (int i=0; i<size; i++)
  
   s.writeObject(elementData[i]);
  
   if (modCount != expectedModCount) {
  
   throw new ConcurrentModificationException();
  
  }
  ```

- 每次序列化时，先调用 defaultWriteObject() 方法序列化 ArrayList 中的非 transient 元素，然后遍历 elementData，只序列化已存入的元素，这样既加快了序列化的速度，又减小了序列化之后的文件大小。

## fail-fast机制

- 是java集合的一种错误检测机制，当在迭代集合的过程中该集合在结构上发生改变的时候，就有可能会发生fail-fast，即抛出 ConcurrentModificationException异常。

- 例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出 ConcurrentModificationException 异常，从而产生fail-fast机制。**OR** 单线程遍历list过程中删除一个元素，也会引发fail-fast。

- 原因：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。

- 解决办法：

  - 1、在遍历过程中，所有涉及到改变modCount值得地方全部加上synchronized。
  - 2、在单线程的遍历过程中，如果要进行remove操作，可以调用迭代器的remove方法而不是集合类的remove方法。因为迭代器的remove方法删除完元素后会将expectedModCount更新为当前的modCount，这样进行检测时就不会报错。

  - 3、使用CopyOnWriteArrayList来替换ArrayList，低层是用volatile transient修饰的数组array。该容器在对插入、修改、移除操作时，并不是在原数组上进行修改，而是将原数组拷贝一份，在新数组上进行修改，待完成后，才将指向旧数组的引用指向新数组。但 CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。（对副本修改，对原集合读，最后改指针）

## fail-safe机制

采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。所以，在遍历过程中对原集合所作的修改并不能被迭代器检测到，故不会抛 `ConcurrentModificationException` 异常。（对副本读，对原集合修改，缺点是不能保证遍历的是最新内容）

## HashMap和HashTable区别

|                                | HashMap                               | HashTable                                        |
| ------------------------------ | ------------------------------------- | ------------------------------------------------ |
| 线程是否安全                   | 非线程安全                            | 线程安全，内部方法用synchronized修饰             |
| 效率                           | 高                                    | 低（淘汰了都）                                   |
| 对null键和null值的支持         | 可以有一个null键，多个null值          | 不能有null键和null值，会抛出nullpointerException |
| **初始化（创建时不指定容量）** | 初始容量：16   扩容时：n*2            | 初始容量：11 扩容时：n*2 + 1                     |
| **初始化（指定容量）**         | 使用tableSizeFor方法，扩充为2的幂次方 | 直接使用指定值                                   |
| 底层数据结构                   | 1.8后，有将链表转成红黑树的操作       | 没有这样的机制                                   |
| 迭代器                         | Iterator（fail-fast）                 | Enumeration                                      |

## HashMap和HashSet的区别

| HashMap                          | HashSet                                                      |
| -------------------------------- | ------------------------------------------------------------ |
| 实现了Map接口                    | 实现Set接口                                                  |
| 存储键值对                       | 仅存储对象                                                   |
| 调用 `put（）`向map中添加元素    | 调用 `add（）`方法向Set中添加元素                            |
| HashMap使用键（Key）计算Hashcode | HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性 |

## HashMap和TreeMap的区别

TreeMap和HashMap 都继承自`AbstractMap` ，但是需要注意的是`TreeMap`它还实现了`NavigableMap`接口（）`SortedMap` 接口。故TreeMap**多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力。**

|                    | HashMap                           | TreeMap                    |
| ------------------ | --------------------------------- | -------------------------- |
| 数据结构           | 数组+链表/红黑树                  | 数组+红黑树                |
| 排序能力、搜索能力 | 无                                | 有                         |
| 键、值能否为null   | 都可为null，但只能有一个key为null | key不为null，value可为null |

## HashMap

### 1.7 vs 1.8

![image-20201219165744364](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20201219165744364.png)

### HashMap的初始化

#### **初始化（创建时不指定容量）** 

初始容量：16   扩容时：n*2  

#### **初始化（指定容量）**  

使用tableSizeFor方法，扩充为2的幂次方

### HashMap的put操作

![img](https://pic3.zhimg.com/80/58e67eae921e4b431782c07444af824e_720w.png)

①.判断键值对数组table是否为空或长度为0，是的话执行resize()进行扩容；

②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；

③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；

④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；

⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；

⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

#### 多线程put产生的问题

1.7：会产生环形链表，导致死循环or数据丢失

1.8：数据丢失

### HashMap的get操作

```java
public V get(Object key) {
        //定义一个Node对象来接收
        Node<K,V> e;
        //调用getNode()方法，返回值赋值给e，如果取得的值为null，就返回null，否则就返回Node对象e的value值
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

 //取hash值方法，HashMap的put方法的也是调用了这个方法，get方法也调用这个方法，保证存取时key值对应的hash值是一致的，这样才能正确对应 
 static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
    
     
final Node<K,V> getNode(int hash, Object key) {
        //定义几个变量 
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        //首先是判断数组table不能为空且长度要大于0，同时把数组长度tab.length赋值给n
        if ((tab = table) != null && (n = tab.length) > 0 &&
             //其次是通过[(n - 1) & hash]获取key对应的索引，同时数组中的这个索引要有值，然后赋值给first变量
            (first = tab[(n - 1) & hash]) != null) {
            //这个first其实就是链表头的节点了，接下来判断first的hash值是否等于传进来key的hash值
            if (first.hash == hash && 
                //再判断first的key值赋值给k变量，然后判断其是否等于key值，或者判断key不为null时，key和k变量的equals比较结果是否相等
                ((k = first.key) == key || (key != null && key.equals(k))))
                //如果满足上述条件的话，说明要找的就是first节点，直接返回
                return first;
            //走到这步，就说明要找的节点不是首节点，那就用first.next找它的后继节点 ，并赋值给e变量，在这个变量不为空时   
            if ((e = first.next) != null) {
                //如果首节点是树类型的，那么直接调用getTreeNode()方法去树里找
                if (first instanceof TreeNode)
                     //这里就不跟进去了，获取树中对应key的节点后直接返回
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                //走到这步说明结构还是链表    
                do {
                    //这一步其实就是在链表中遍历节点，找到和传进来key相符合的节点，然后返回
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                  //获取e节点的后继节点，然后赋值给e，不为空则进入循环体  
                } while ((e = e.next) != null);
            }
        }
        //以上条件都不满足，说明没有该key对应的数据节点，返回null
        return null;
    }	
```



### 计算hash值为何要进行无符号右移？

让生成的哈希值尽量均匀，进而使得到的索引值更均匀。数组长度不会很大，在0~2^16范围内，而hashCode（）范围在0~2^32, 若直接拿这个**hashCode值**与**数组长度-1**相与，高16位不会参与运算，故需无符号右移16位异或，使高位参加运算，最终使计算的索引值更加均匀。 

### **为什么使用异或而不是&和|呢？**

因为&和|偏向于1和0的结果，而异或的结果0和1比较均匀。

### 扩容后需要重新计算key的hash值来得到索引嘛？

jdk1.8开始不用，扩容后，n-1的二进制表示中会多一个1，只需去看key原先的hash在对应位置上的数即可，若为**1**，**新的索引**位置就为**原索引+oldCap**，若为**0**，则**不变**。

jdk1.7及之前版本需要。

hashmap1.7和1.8其他不同：

1、添加元素时，1.7的链表采用头插法，1.8遍历链表。

2、数据结构，1.7 数组+链表  ； 1.8数组+链表/红黑树

### 链表和红黑树之间的转化？

1、链表转化成红黑树的时机：当数组长度大于64时，若链表长度大于8则进行转化（成功put进第九个元素后立即进行转化）。（数组长度小于64，优先扩容）

2、红黑树退化成链表的时机：在resize时，若红黑树中结点的个数小于6时进行转化。

### 为什么树化的阈值是8？

当桶中结点个数为8时，出现的几率是亿分之6的，**因此常见的情况是桶中个数小于8的情况，此时链表的查询性能和红黑树相差不多，因为转化为树还需要时间和空间，所以此时没有转化成树的必要。**

然后亿分之6这个概率是建立在良好的hash算法情况下，例如String，Integer等包装类的hash算法。如果一旦发生桶中元素大于8，说明是不正常情况，可能采用了冲突较大的hash算法，此时桶中个数出现超过8的概率是非常大的，可能有n个key冲突在同一个桶中，此时再看链表的平均查询复杂度和红黑树的时间复杂度，空间换时间，转成红黑树。

### **红黑树如何排序？**

如果key中的对象实现了Comparable接口，按此接口中的规则进行排序，否则，通过class类名进行排序。

### 哈希冲突的解决方法？

开放定址法（包括线性探测、再平方探测、伪随机探测）、再哈希法、拉链法、建立公共溢出区



## HashMap&Hashtable&ConcurrentHashMap

HashMap不支持多线程，会产生环形链表（1.7）、会丢失数据（1.7, 1.8)。

Hashtable支持线程，采用synchronized锁整张表。

ConcurrentHashMap支持多线程

## ConcurrentHashMap的实现、put方法

### 1.8

#### 原理

采用CAS和synchronized（只锁链表首节点/红黑树的根节点）保证安全，数据结构类似HashMap1.8

#### **put**方法解析

1. 判断key、value是否为null，是的话抛空指针异常。
2. 若table为null或长度为0，调用initTable方法初始化。
3. 否则判断索引位置上是否为**空**，是的话通过**CAS**插入新节点。
4. 若非空，判断结点的hash值是否为-1，是的话说明处于扩容状态，当前线程帮忙迁移数据。
5. 否则，给桶中第一个节点加同步锁（Sync），进入同步代码块，代码块内的内容包括：如果hash值>=0，说明是链表结构，遍历链表更新节点或插入新节点；否则，判断是否为树节点，是的话通过putTreeVal方法往红黑树中插入节点。
6. 同步代码块执行过后，如果bincount不为0，说明put操作改变了数量，接下来判断节点长度是否超过8，超过则转化成红黑树。（在锁外面的原因是，treeifyBin函数内部有同步锁）

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
		if (key == null || value == null)
			throw new NullPointerException();
		int hash = spread(key.hashCode());
		int binCount = 0;
		for (Node<K, V>[] tab = table;;) {
			Node<K, V> f;
			int n, i, fh;
			if (tab == null || (n = tab.length) == 0)
				tab = initTable();
			else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
				//1、如果相应位置的Node还未初始化，则通过CAS插入相应的数据；
				if (casTabAt(tab, i, null, new Node<K, V>(hash, key, value, null)))
					break; // no lock when adding to empty bin
			} else if ((fh = f.hash) == MOVED)
				tab = helpTransfer(tab, f);
			else {
				//2、如果相应位置的Node不为空，且当前该节点不处于移动状态，
			    //则对该节点加synchronized锁，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点；
				V oldVal = null;
				synchronized (f) {
					if (tabAt(tab, i) == f) {
						if (fh >= 0) {
							......
							}
						 //3.如果该节点是TreeBin类型的节点，说明是红黑树结构，则通过putTreeVal方法往红黑树中插入节点；
						} else if (f instanceof TreeBin) {
							......
							}
						}
					}
				}
				//4、如果binCount不为0，说明put操作对数据产生了影响，如果当前链表的个数达到8个，
				//则通过treeifyBin方法转化为红黑树，如果oldVal不为空，
				//说明是一次更新操作，没有对元素个数产生影响，则直接返回旧值；
				if (binCount != 0) {
				......
				}
			}
		}
		//5、如果插入的是一个新节点，则执行addCount()方法尝试更新元素个数baseCount；
		addCount(1L, binCount);
		return null;
	}
```

#### size方法

`baseCount` 记录元素数量，每次元素数量变更之后，将会使用 `CAS`方式更新该值，若更新失败，说明有多个线程并发增加或删除元素，`baseCount` 更新冲突，将会启用 `CounterCell`数组（数组大小和CPU数量有关,不能超过CPU数），数组内的每个ConuterCell都是一个独立的计数单元。每个线程通过使用 `CAS` 方式将数量更新到数组对应的位置（该位置通过当前线程探针哈希到的，即ThreadLocalRandom.getProbe() & (n-1)）。

如果 `CAS` 更新 `counterCells` 数组某个位置出现多次失败，这表明多个线程在使用这个位置。此时将会通过扩容 `counterCells`方式，再次减少冲突。

最终只要计算 `baseCount` 与 `counterCel ls`总和，就能得到元素数量，整个过程都不需要加锁。

仔细回味一下，`counterCells` 也是通过类似分段锁思想，减少多线程竞争。

### 1.7

#### 原理

对数组分段成若干个Segment，Segment继承了ReentrantLock。数据结构为Segment+链表。	

​	（1）Segment中的HashEntry中的value和next被**volatile**修饰，保证了多线程读写过程中的可见性。

​	（2）**ConcurrentHashMap的构造函数**根据concurrenyLevel计算ssize，sshift，根据initialCapacity计算每个segment中HashEntry数组长度，并且初始化第一个segment。剩余的Segments采用的是延迟初始化的机制：每次put之前都需要检查key对应的Segment是否为null，如果是则调用ensureSegment()以确保对应的Segment被创建。![image-20200728102942766](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200728102942766.png)

#### 如何确定插入元素的位置？

![image-20200728103521447](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200728103521447.png)

 1.2两步位于Map的put方法， 

```
j=(key.hash>>>(32-sshift))&(ssize-1)=(key.hash>>>segmentShift )&segmentMask
```

ssize为segment数组长度，sshift由ssize取对数得到。  

3.4两步位于Segment的put方法，进入该方法会先tryLock尝试加锁（tryLock不会阻塞，成功返回true 失败false；Lock会阻塞，失败则进入同步队列进行阻塞等待）

**第2、3步计算下标的区别：**

​			![image-20200728103913817](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200728103913817.png)。这样做是为了避免分配到用一个segment中的元素扎推，连在同一个链表上。

#### **put**方法解析

1. 首先tryLock（）尝试获取锁，如果获取失败说明存在竞争，则进行自旋尝试获取锁。

2. 获得锁之后，计算索引位置，若该位置不为空，则遍历该hashEntry，若遇到相等的key，则覆盖旧的value；

3. 若为空，新建一个hashEntry，接着先判断是否需要扩容，不需要则直接放入到segment中，否则对该segment进行扩容，创建容量为原来两倍的数组，并将原数组里的元素rehash之后放入。

   ```java
   final V put(K key, int hash, V value, boolean onlyIfAbsent) {
              // 1. 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry
               HashEntry<K,V> node = tryLock() ? null :
               	// 尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用scanAndLockForPut()
                   //自旋获取锁。
                   scanAndLockForPut(key, hash, value);
               V oldValue;
               try {
                   HashEntry<K,V>[] tab = table;
                   int index = (tab.length - 1) & hash;
                   HashEntry<K,V> first = entryAt(tab, index);
                   for (HashEntry<K,V> e = first;;) {
                       if (e != null) {
                           K k;
                           // 2. 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 
                           //    是否相等，相等则覆盖旧的 value
                           if ((k = e.key) == key ||
                               (e.hash == hash && key.equals(k))) {
                               oldValue = e.value;
                               if (!onlyIfAbsent) {
                                   e.value = value;
                                   ++modCount;
                               }
                               break;
                           }
                           e = e.next;
                       }
                       // 3. 为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容
                       else {
                           if (node != null)
                               node.setNext(first);
                           else
                               node = new HashEntry<K,V>(hash, key, value, first);
                           int c = count + 1;
                           if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                               rehash(node);
                           else
                               setEntryAt(tab, index, node);
                           ++modCount;
                           count = c;
                           oldValue = null;
                           break;
                       }
                   }
               } finally {
                   unlock();
               }
               return oldValue;
           }
   ```


#### size方法

尝试两次不锁住segment的方式，统计各segment中元素数量，如果在这个过程中modCount发生变化，则再采用加锁的方式统计。

# 3.JVM

## 3.1 JVM运行流程

加载-连接（验证-准备-解析）-初始化

加载：

- 通过类的完全限定名获取定义该类的二进制字节流（.class）
- 将该字节流表示的静态存储结构转化为运行时的存储结构
- 在内存中生成一个代表该类的class对象，作为方法区中该类各种数据的访问入口

验证：确保.class文件中包含的信息符合虚拟机的要求，如果验证成功，进入下一步 。

准备：为**类变量**分配**方法区内存**并初始化零值。若类变量是常量，则初始化为代码中设定的值。

解析：将常量池的符号引用替换为直接引用的过程。（某些情况下，解析和初始化可以交换顺序，这是为了支持动态绑定）

初始化：虚拟机执行类构造器 <clinit\>() 方法的过程，真正执行java程序代码，**按代码**去初始化**类变量和其他资源**。

​	<clinit\>() 是由编译器自动收集类中所有**类变量的赋值动作**和**静态语句块中的语句**合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，**静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问**。

## 3.2 Java的内存分配

可以粗分为堆内存和栈内存，也可按如下方式分：

- 线程共享：堆、方法区（1.8后位于直接内存）、直接内存

- 线程私有：程序计数器、本地方法栈、虚拟机栈

### 3.2.1 程序计数器

记录下一条要运行的指令的地址。**唯一**不会出现**OOM**的区域.

字节码解释器通过改变程序计数器的值来选取下条要执行的指令，实现流程控制。此外，在线程切换时，可以通过读取计数器，从上次的位置继续往下执行。

### 3.2.2 虚拟机栈

由栈帧组成，每个栈帧包含：

- 局部变量表：存放基本数据类型、引用类型变量（可能是指向对象起始地址的**指针**or代表对象的**句柄**，这是对象访问定位的两种方式。句柄中保存对象实例数据和类型数据各自的地址。）。
- 操作数栈
- 动态链接
- 方法出口

虚拟机栈中存在OutOfMemoryError和StackOverFlowError：

前者：若虚拟机允许动态扩展，且当前线程请求栈时内存用完，无法再扩展了，就抛出此异常。

后者：若虚拟机不允许动态扩展，当前线程请求栈的深度超过了最大深度，抛出此异常。

Java中调用方法函数时，会往虚拟机栈中压入栈帧，调用结束（可通过return语句和抛出异常使调用结束）后弹出。

### 3.2.3 本地方法栈

和虚拟机栈作用类似，只不过是为native方法服务，虚拟机栈是为Java方法（字节码）服务。

### 3.2.4 堆

占用内存最大，用于存放对象实例、数组，会出现OOM。Java1.7后，**运行时常量池**位于堆中，包含字面量和符号引用。**字符串常量池**也在堆中。

#### 3.2.4.1（扩展：class常量池、运行时常量池和字符串常量池的区别？ 

- 在java文件被 *编译* 为class文件时，**class常量池**在class文件中生成，每个类一个。

- 在类的 *加载* 阶段后，jvm将**class常量池**的内容（包括字符串字面量）存放到元空间的**运行时常量池**，每个类都有一个。

- 在类的 *准备* 阶段后，在堆中生成字符串对象实例，并将这些对象实例的引用值放入**字符串常量池**，这个池只有一份，被所有类共享。

- 类的 *解析* 过程中，**运行时常量池**会去查询**字符串常量池**，把符号引用变为直接引用，保证**运行时常量池**引用的字符串与**字符串常量池**中的引用一致。

  ）

堆分为eden、s0、s1、tentired四个区域，目的是更好（如：无内存碎片）、更快的回收内存。

回收的流程：

1. 对象在eden区分配
2. 将eden区和s0中存活的对象复制到s1区域且对象年龄+1，若年龄超过阈值(-XX:MaxTenuringThreshold)则进入老年代；其他对象则回收掉。
3. s0和s1区交换指针，这样使s1永远是空的区域。

### 3.2.5 方法区

存放被虚拟机加载的**类信息、常量、类变量、即时编译后的代码。**

### 3.2.6 直接内存

不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，可能出现OOM。

## 3.3 堆和栈区别

|                | 堆                        | 栈                                                           |
| -------------- | ------------------------- | ------------------------------------------------------------ |
| 功能           | 存放实例对象              | 存放局部变量、操作数栈、动态链接、方法出口等信息             |
| 线程独占or共享 | 线程共享                  | 线程独占                                                     |
| 异常错误       | 无空间存放实例对象，抛OOM | 无空间进行栈的扩展，抛OOM；请求栈的深度超过虚拟机栈最大深度，抛栈溢出 |
| 内存大小       | 大（-Xms、Xmx）           | 小（-Xss）                                                   |

## 3.4 为什么字符串常量池处于堆区

java6及更老的版本中，放在永久代（方法区）中，但由于其空间小（默认4m大小），大量使用intern会导致OOM，所以在7中移到了堆中。

## 3.5 方法区的变更

java7之前，运行时常量池和字符串常量池都在永久代中，java7将字符串常量池移到堆中，java8用元空间取代永久代。

## 3.6 类的死亡判定

1、类的所有实例已被回收

2、类的classloader被回收

3、类的class对象没被引用

## 3.7 对象的死亡判定

### 引用计数法

给对象一个引用计数器，每被引用一处，计数器+1；引用失效，-1；计数器为0，死亡。（存在循环引用的问题）

### 可达性分析法

以GC Roots作为起点，向下搜索，节点形成的路径叫引用链，不在其中的对象即不可用。。

### 3.7.1 哪些可作为GC Roots？

- **虚拟机栈局部变量表**中  引用的对象
- **本地方法栈JNI**中  引用的对象
- **方法区类变量**  引用的对象
- **方法区常量**   引用的对象

### 3.7.2 可达性分析法的原理

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228000932496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NTI2NTcz,size_16,color_FFFFFF,t_70)

队列执行具体为：虚拟机自动创建低优先级的finalizer线程，并执行队列中对象的finalize方法。

## 3.8 四种引用及运用场景

- 强引用

  对象必不可少，即使内存不足也不会对其进行回收，宁愿抛OOM。

  ```java
  String s = new String("cmy");
  s=null;//通过将引用赋值为null，可中断对象和强引用的关联，使GC回收对象。
  ```

  使用场景：new一个对象

- 软引用

  有软引用的对象，只当内存不足时才会被回收。

  ```java
  String s = new String("cmy");
  SoftReference<String> sf = new SoftReference<String>(s);
  ```

  使用场景：创建缓存

- 弱引用

  GC线程一旦发现只有弱引用的对象，该对象就会被回收。

  ```java
  Object obj = new Object();
  WeakReference<Object> wf = new WeakReference<Object>(obj);
  obj = null;
  ```

  使用场景：WeakHashMap类中的key

- 虚引用

  不会决定对象的生命周期；必须和**引用队列**一起用。

  ```java
  Object obj = new Object();
  PhantomReference<Object> pf = new PhantomReference<Object>(obj, null);
  obj = null;
  ```

  使用场景：主要用来跟踪对象被垃圾回收的活动。

## 3.9 垃圾回收算法

- 标记-清除

  标记阶段：标记存活对象

  清除阶段：回收未被标记的对象，还会判断回收后的分块和前一个空闲分块是否连续，连续则合并。具体地说，它的回收对象就是把对象作为分块，连接到“空闲链表”，之后分配内存空间时遍历这个链表，如果遍历到的分块大小刚好，则直接返回，若分块过大，则将该分块分割，获得刚好大小的分块，多出来的返回给链表。

  优点：标记和清除的效率不高。

  缺点：产生大量内存碎片，无法给大对象分配内存

- 标记-整理

  让存活的对象向一端移动，然后直接清理端边界外的内存。

  优点：无内存碎片

  缺点：需要移动对象，效率低

- 复制

  将内存分为相同大小的两块，每次使用一块，当该块内存使用完后就将存活对象复制到另一块，并清理内存。

  优点：效率高，无内存碎片

  缺点：内存利用率低。

  PS. 在虚拟机中的具体实现为：新生代=eden+s0+s1，每次使用eden和s0，回收时，将这两区域的存活对象复制到s1并清理内存，接着交换s0和s1的指针。eden : s0 : s1 = 8 : 1 : 1，内存利用率达到90%。如果每次存活对象的大小大于10%，通过分配担保机制，将存活的对象存到老年代。

  **分配担保机制**：

  1. 在发生Minor GC之前，虚拟机会进行检查，**只要老年代的连续空间大于新生代对象总大小** 或者**历次晋升的平均大小就会进行Minor GC，** 否则将进行Full GC。
  2. Minor GC后，
     - 若存活的对象大小**小于**Survivor区的大小，直接进入Survivor区；
     - 若存活的对象大小**大于**Survivor区的大小，却小于老年代大小，那么存活的对象直接进入老年代。
     - 若存活的对象大小**大于**老年代大小，那么此时机会触发一次Full GC，对老年代和新生代统一做一次垃圾回收，腾出空间，方便让Minor GC后存活的对象可以进入老年代。

- 分代回收

  新生代：复制算法

  老年代：标记清除或标记整理

## 3.10 垃圾收集器

- 新生代收集器
  - Serial收集器

    串行、单GC线程、简单高效

  - ParNew收集器

    Serial的多线程版本、唯一能和CMS配合使用的

  - Parallel Scavenge

    多线程、以吞吐量优先（其他目标是尽可能缩短 垃圾收集时 用户线程的 停顿时间）

    吞吐量：CPU 用于运行用户程序的时间 占 总时间 的比值

- 老年代收集器

  - Serial Old

    串行、单GC线程、标记-整理

  - Parallel Old

    Parallel Scavenge的老年代版本，以吞吐量优先

  - CMS

    采用标记-清除算法。

    1. 初始标记：有且仅有一个GC线程运行（用户线程停顿），标记GC ROOTS能直接关联的对象
    2. 并发标记：一GC、多用户线程并发执行（无停顿），进行GC Roots Tracing，耗时最长。
    3. 重新标记：多个GC线程运行（用户线程停顿），修正上一阶段因用户程序继续运行而导致标记发生变动的对象的标记记录，初始标记<耗时<并发标记。
    4. 并发清除：一GC，多用户（无停顿）。

    缺点：

    - 吞吐量低：低停顿时间是以牺牲吞吐量为代价。
    - 无法处理浮动垃圾。浮动垃圾：并发标记阶段用户线程运行产生的垃圾，这部分垃圾要等到下一次GC时才能回收，因此，CMS要在老年代预留空间存放这类垃圾，如果预留空间不够，就会出现concurrent Mode Failure，进而引起full GC。
    - 标记-清除算法导致空间碎片，出现在老年代中找不到足够大连续空间分配对象，导致提前触发fullGC。

- G1收集器

  - 可对新生代、老年代一起进行垃圾回收。
  - 停顿时间短、吞吐量高。

  - 将堆划分成大小相同的区域，每个区域可单独进行垃圾回收。
  - 通过记录每个区域的垃圾回收时间及回收得到的空间，维护一个优先列表，基于此，根据允许的收集时间，可优先回收价值最大的区域。
  - 每个区域都有一个Remembered Set，记录该区域对象的引用对象所在的区域。借于此，在可达性分析时可避免全堆扫描。
  - 运行步骤：
    1. 初始标记：同CMS（停顿）
    2. 并发标记：同CMS（不停顿）
    3. 最终标记：修正上一步因用户线程运行而导致标记发生变动的对象的标记记录，变动是被记录在Remembered Set Logs里，在该阶段会把logs中的数据合并到Remembered Set中。（停顿）
    4. 筛选回收：对各区域的回收价值和成本进行排序，根据期望的GC停顿时间制定回收计划。（停顿）
  - 优点：
    - 能对空间进行整合：整体基于“标记-整理”，局部（区域之间）基于“复制”。无内存碎片产生
    - 停顿可预测

## 3.11 Full GC的触发时机及如何减少FullGC

- 调用System.gc() -- 通过-XX:+ DisableExplicitGC禁止调用该方法
- 老年代空间不足 -- 不要创建过大的对象及数组/尽量让对象在MinorGC阶段被回收
- 空间分配担保失败 -- 增大老年代空间
- JDK1.7及之前版本中的永久代空间不足。若full GC后仍回收不了则抛OOM -- 增大永久代空间
- CMS 的GC过程中，老年代空间不足以存放浮动垃圾，触发full GC。-- 增大survivor、老年代空间。

### 3.11.1 减少fullGC的补充

- 对象不使用时设为null
- 少使用类变量，因其属于全局变量，不被GC回收
- 分散对象创建/删除的时间
- 少使用finalize
- 增大-Xmx

## 3.12 方法区需要GC吗？

方法区可以对**死亡的类**和**废弃常量**（没在被引用）进行GC。

但方法区的回收效率低于堆，因此规范规定虚拟机可不实现GC。

## 3.13 查看GC状态的命令

```
jstat -gcutil <pid> <period> <times> 
```

每隔<period>毫秒对进程<pid>查询<times>次。

## 3.14 CPU100%的排查过程

1. top命令查看各进程的cpu使用情况，找到占用率最高的**进程pid**
2. 查看该进程下各线程的cpu使用情况，`top -Hp 进程pid`,找到占用率最高的**线程pid**
3. 执行`printf "%x\n" 线程pid`得到对应的16进制表示
4. `jstack 进程pid | grep 线程pid的16进制表示` 查看指定进程下的指定线程状态
   - 若是用户线程，则通过线程的堆栈信息查看其具体在哪处代码的运行消耗cpu
   - 若是VM Thread，则通过`jstat -gcutil <进程pid> <period> <times> `监控GC情况，并通过`jmap dump:format=b,file=<filepath> <进程pid>` 导出当前的内存数据。之后将这些数据导入mat工具中分析出各对象的内存消耗情况。

## 3.15 CPU非100%但系统仍缓慢的排查过程

- 若是接口调用比较耗时，且不定时出现，可通过压测方式加大阻塞点出现的频率，从而通过jstack查看堆栈信息，找到阻塞点
- 如果通过jstack可查看到死锁状态，则可检查发生死锁的两线程的具体阻塞点，处理相应的问题。
- 若是某个功能突然出现停滞，可通过多次导出jstack日志的方式对比哪些用户线程是一直处于等待状态的。

## 3.16 对象创建过程

1. 类加载检查

   虚拟机遇到new指令，先去检查类是否加载、连接、初始化过。若无，则执行相应的类加载过程。

2. 分配内存

   从堆中划分内存空间。分配方式：指针碰撞、空闲列表。

   ![img](https://images.xiaozhuanlan.com/photo/2019/3af6db384fba7d42e2f9a07fb57b72d8.)

   分配并发问题：CAS+失败重试 或者 TLAB

3. 初始化零值

   虚拟机将分配到的内存空间都初始化为零值（不包括对象头）。目的是保证对象的实例字段可以不赋初始值就直接用。

4. 设置对象头

   包括类元数据地址、对象哈希码、GC分代年龄、锁标志位等。

5. 执行初始化init方法

   按程序员所写代码进行初始化。

## 3.17 对象访问定位方法

直接指针、句柄两种。

- 直接指针：局部变量表中的reference直接指向堆中的对象，并通过对象的类元数据地址可访问到方法区中的类元数据。（优点：速度快，相比句柄方式少一次指针定位的开销）
- 句柄：局部比例比中的reference指向堆中的句柄池，池中存放着对象的地址和对象类元数据地址。（reference存放稳定的句柄地址）

## 3.18 类加载过程

1. 加载

   - 根据类全限定名找到二进制字节流（如.class文件）
   - 将字节流表示的静态存储结构转化为方法区的运行时存储结构
   - 在堆中创建class对象，作为方法区该类各数据的访问入口

2. 验证

   确保二进制字节流（.class文件）符合当前虚拟机规范，且是安全的。

3. 准备

   对类变量**分配方法区内存**并进行**零值初始化**，若类变量还是一个常量则按代码初始化。

4. 解析

   常量池的符号引号转为直接引用。

5. 初始化

   虚拟机执行clinit方法，即按所写的java代码进行初始化。

## 3.19 类初始化时机

对类进行主动引用时，具体地：

- 遇到new、getstatic、putstatic、invokestatic四条字节码指令，若类无初始化则do it！
  - new：实例化对象
  - getstatic：读取类变量
  - putstatic：设置类变量
  - invokestatic：调用类的静态方法
- 进行反射调用的时候，若类无初始化则do it！
- 初始化类时，若其父类未初始化，则先触发父类的初始化。
- 虚拟机启动时，会先初始化包含main方法的类，也就是主类。

## 3.20 类加载器

- 启动类加载器

  - 用C++实现，是虚拟机自身的一部分，无法被程序直接引用，但可在自定义类加载器时，使父类加载器为null，即可将加载请求委派给启动类。
  - 负责将存放在JAVA_HOME/lib目录中、且被虚拟机识别的类库加载到虚拟机内存中。

  - 其他加载器都是java实现，独立于虚拟机，继承自lang.ClassLoader抽象类。

- 扩展类加载器

  负责将JAVA_HOME/lib/ext目录下的类库加载到内存。

- 应用类加载器

  - 负责加载用户类路径（classPath）上指定的类库。
  - 在无自定义类加载器的情况下，应用类是默认使用的类加载器。

- 自定义类加载器

## 3.21 类加载器双亲委派机制

1. 类加载器加载类前，先判断该类是否被加载过，是的话，直接返回加载的类。
2. 否则，将加载请求交给父类加载器处理，只有当父类无法完成时才自己加载。

ps.这里的父类不是继承关系，而是一种优先级关系。

### 3.21.1 好处

**避免重复加载、使基础类得到统一，防止了Java核心api被篡改。**

如果没有使用该机制，而是每个类加载器加载自己，那若我们编写一个java.lang.Object类，程序运行时会出现不同的Object类。

### 3.21.2 不想使用该机制怎么做

- 自定义类加载器时，继承ClassLoader，重写loadClass()方法。
- **通过线程上下文类加载器**，类 java.lang.Thread中的方法 getContextClassLoader()和 setContextClassLoader(ClassLoader cl)用来获取和设置线程的上下文类加载器。如果没有通过 setContextClassLoader(ClassLoader cl)方法进行设置的话，线程将继承其父线程的上下文类加载器。



### 3.21.3 想继续用

自定义类加载器时，继承ClassLoader，重写findClass()方法，无法被父类加载器加载的类会通过该方法加载。

# 4.Java并发



## 4.1 线程和进程的区别

见操作系统部分。

### 4.1.1多进程和多线程区别和应用场景

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190426142051614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTU2NjcwMA==,size_16,color_FFFFFF,t_70)

1）需要频繁创建销毁的优先用线程

原因请看上面的对比。

这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的

2）需要进行大量计算的优先使用线程

所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。

这种原则最常见的是图像处理、算法处理。

3）强相关的处理用线程，弱相关的处理用进程

什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。

一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。

当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。

4）可能要扩展到多机分布的用进程，多核分布的用线程

原因请看上面对比。

## 4.2 线程的实现方式、线程的方法

### 4.2.1 线程的实现方法

继承Thread、实现runnable、callable接口。

两类方式的区别：继承Thread方法等于创建了一种**线程**，实现接口是创建了能在线程中运行的**任务**。

### 4.2.2 线程方法

静态方法：Thread.sleep()、Thread.yield()//声明当前线程已完成重要部分，可以切换给其他同优先级线程执行。

实例方法：

interrput()：中断线程。如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。

join()：在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。

#### 4.2.2.1 wait()和sleep()区别

1、wait是Object类的方法，sleep是Thread类的静态方法

2、wait释放锁， sleep不释放

3、wait()方法调用后需要用同一个对象上的notify/notifyAll唤醒，sleep()到点后自动苏醒。但是，若wait方法指定了时间参数，则也是到点自动苏醒。

## 4.3 线程的状态

6种：NEW、RUNNABLE、BLOCKED、WAITING、TIME_WAITING、TERMINATED

## 4.4 线程上下文切换

[好文1](https://blog.csdn.net/dh554112075/article/details/90696768)、[好文2](https://blog.csdn.net/L13763338360/article/details/104961469/)

CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就会加载这个状态。
**——任务从保存到再加载的过程就是一次上下文切换。**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190530141511526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RoNTU0MTEyMDc1,size_16,color_FFFFFF,t_70)

上下文：保存在内存中的通用寄存器和程序计数器的内容。 切入时，上下文会被放入CPU寄存器中。切出时，将上下文存入内存。

**切出：** 一个线程/进程被剥夺处理器的使用权而被暂停运行
**切入：** 一个线程/进程被系统选中占用处理器开始或继续运行

### 4.4.0 进程和线程的上下文切换区别

线程的切换，虚拟空间内存相同；进程不同，故进程切换的开销  包含了**虚拟地址空间的切换开销**。

### 4.4.1 什么时候发生切换（下面都指线程的上下文切换）

**按导致上下文切换的因素划分，可将上下文切换分为两点：**

- 自发性上下文切换
- 非自发性上下文切换

**自发性上下文切换指线程由于  自身因素  导致的切出。**
通过调用下列方法会导致自发性上下文切换：

- Thread.sleep()
- Object.wait()
- Thread.yeild()
- Thread.join()
- LockSupport.park()

**非自发性上下文切换指线程由于  线程调度器  的原因被迫切出。**
发生下列情况可能导致非自发性上下文切换：

- 切出线程的时间片用完
- 有一个比切出线程优先级更高的线程需要被运行
- 虚拟机的垃圾回收动作

### 4.4.2 切换的开销

直接开销：

- 切换虚拟地址空间（仅**进程**有此开销、注意这会导致**快表失效**。虚拟地址详见操作系统章节）
- 操作系统保存恢复上下文所需的开销
- 切换内核栈

间接开销：

- 处理器高速缓存失效进而重新加载的开销

## 4.5 ThreadLocal

访问过ThreadLocal变量的线程都会在本地留下该变量的副本。具体是存放在各线程拥有的ThreadLocalMap数据结构（Thread源码中就有的）中

ThreadLocal对象的set方法工作流程：

1.获取当前线程 

2.获取当前线程拥有的ThreadLocalMap对象

3.调用ThreadLocalMap对象的set（key, value）方法，key为ThreadLocal对象，value为Object对象（ThreadLocal对象调用set方法设置的值）。

```java
//ThreadLocal类的set()方法    
	public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }
    ThreadLocalMap getMap(Thread t) {
        return t.threadLocals;
    }
```

### 4.5.1ThreadLocalMap内存泄漏问题

ThreadLocalMap 中使用的 **key 为 ThreadLocal 的弱引用**,而 **value 是强引用**。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法

## 4.6 AQS

AQS为创建锁和同步器的框架,Semaphore、ReentrantLock、CyclicBarrier、ConutDownLatch等都基于此实现。

**核心思想**：若共享资源空闲，则将当前请求该资源的线程设为工作线程；若资源被已被占用，这时需要一套线程阻塞等待和被唤醒时分配锁的机制，该机制具体是用CLH队列实现,将暂时获取不到锁的线程加入队列。

**AQS**使用volatile int型的变量**state**来代表**同步状态**，使用**CLH队列**实现请求资源线程的**排队工作**。AQS具体只需程序猿实现共享资源**state**的获取和释放方式，**线程等待队列**的维护在顶层已实现好。

state有两种共享方式：exclusive和share，exclusive又分为公平锁和非公平锁。

AQS的设计基于**模板方法模式**，大体分为两步：

1、程序员继承AQS类并重写指定模板方法（一共就五个可以重写的方法：

```java
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。

```

）

2、将AQS组合在自定义同步器的实 现中，并调用1中重写的模板方法。

### 4.6.1 CounDownLatch和cyclicBarrier的区别

![图片](https://mmbiz.qpic.cn/mmbiz_png/hvUCbRic69sD3bnIttXBhf9tMcslCw4jwbg6xuJaN1YIpd6yPetx7wia6QJx2mJu6CEXY2smZ1swztYtFLZwJAvA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 4.7 volatile关键字

[好文](https://mp.weixin.qq.com/s/Oa3tcfAFO9IgsbE22C5TEg?utm_source=qq&utm_medium=social&utm_oi=1028643064004415488)

`volatile`**的内存屏障策略非常严格保守，**非常悲观且毫无安全感的心态：

> **在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；
>  在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；**

## 4.8 synchronized关键字

### 4.8.1 了解什么？

作用：保证多线程访问资源的同步性。 使被其修饰的方法、代码块，同一时刻只能被一个线程访问。

java1.6之前，是重量级锁，效率低，因为monitor是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的，如果要挂起或者唤醒一个线程，都需要操作系统帮忙，需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。

用法：修饰静态方法、实例方法、代码块（指定加锁对象，可以是类对象or实例对象）

### 4.8.2 原理

1、修饰同步代码块

monitorenter和monitorexit指令，前者指向代码块开始位置，后者指向结束位置。

执行 monitorenter时，线程试图获取monitor对象，当monitor中的计数器为0**或者**owner对象为当前线程则成功获取，并将计数器加1；

执行monitorexit时，计数器减1，为0时释放。

2、修饰方法

通过ACC_SYNCHRONIZED标识，指明方法为同步方法，JVM通过该标志进行判定后，执行相应的同步调用。

## 4.9 锁的升级过程

JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

**具体地，**

刚实例化的对象会**偏向**第一个访问他的线程，使用CAS操作将线程ID记录到对象头当中，并将偏向标志位置为1，之后当有线程访问的时候，会比较线程ID，相同则可直接使用。如果有第二个线程 访问这个对象，他会看到这个对象的偏向情况，并去检查原来持有该锁的线程是否依然存活，若挂了，则将对象变为无锁状态，重新偏向新的线程，若没挂，则执行原来线程的操作栈，看其是否还要 用到这个对象，如果仍然需要 ，则**膨胀成轻量级锁**，否则，将对象变为无锁状态，偏向新的线程。

**轻量级锁**认为存在竞争但是程度很轻，两个线程对一个锁的操作是错开的，或者自旋一下，一个线程就能等到另一个线程释放锁。 但是，当自旋次数超过阈值，或一个线程持有锁，一个在自旋，又有另一个线程来竞争，那么就会**变成重量级锁**，使得除持有锁之外的线程都阻塞。

轻量级锁加锁过程：虚拟机栈中创建一个名为lock record的空间，将对象头中的mark word拷贝进去 ，成功后使用CAS操作将锁对象头的mark word更新为指向lock record的指针，并将lock record中的owner指向锁对象的mark word。

重量级锁工作流程：当多个线程同时访问一段同步代码时，首先会进入 Entry Set。当线程获取到对象的monitor 后进入 The Owner 区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。

### 4.9.1 对象的monitor何时生成？

每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成

## 4.10 Synchronized和ReentrantLock区别？

同：都是可重入锁。同一线程可再次获得自己拥有的锁。

不同：

1、前者基于JVM实现，没有直接暴露给我们，后者基于JDK层面实现，可以查看到源代码。

2、前者为非公平锁，后者可以通过其构造函数设定为是否公平。

3、后者有等待可中断机制，通过lock.lockInterruptibly（）实现，等待的线程可以选择放弃等待。

4、后者可实现选择性通知。一个lock对象中可创建多个condition对象，每个condition能绑定多个线程，调用指定condition的signalAll方法即可唤醒绑定在它上面的所有线程。

### 5.1.1 讲一下ReentrantLock的公平锁和非公平锁实现

公平锁：

若state为0，先去查看等待队列中是否有线程，若无，则采用CAS操作尝试将state设为1，若成功，则获得该锁并返回true，否则返回false。

若state非0，则判断当前线程是否持有该锁，有则对state加1返回true，否则返回false。

```java
protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &&
                    compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
```

非公平锁：

若state=0，则使用**CAS操作**尝试将state设为1，若成功，则当前线程获得锁并返回true，否则返回false；若state非0，判断当前线程是否持有该锁，有则state+1，返回true，否则直接返回false。

```java
final boolean nonfairTryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0) // overflow
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
```



## 4.11 JUC原子类

四类，基本类型、数组类型、引用类型、对象的属性修改类型。

1、基本类型

整型、长整型、布尔型原子类。

2、数组类型

整型数组、长整型数组、引用类型数组原子类。

3、引用类型

引用类型原子类 ：AtomicReference

带版本号的引用类型原子类：AtomicStampedReference，可以解决ABA问题

带有标记位的引用类型原子类：AtomicMarkableReference

4、对象的属性修改类型

整型字段的更新器原子类：AtomicIntegerFieldUpdater

长整型字段的更新器原子类：AtomicLongFieldUpdater

### 4.11.1 AtomicInteger如何保证原子性

使用CAS+volatile和native方法来保证。

首先，该类的数值大小保存在变量value中，该变量为volatile变量，所以JVM能保证任何线程都能拿到该变量的最新值。

其次，就是该类的静态代码块中会使用native方法，即Unsafe类的objectFieldOffest方法，通过反射方式获取到value的内存地址，用于更新value时使用到的CAS操作。

## 4.12 多线程读要加锁吗？

分三种情况。

1、无写线程。不用加锁

2、有写线程，且写操作与当前的值无关联，比如a=b+c，则只需要考虑给变量加上volatile关键字，如果有多个写线程则写方法要加锁。

3、有写线程，且写操作依赖当前值，比如i++ (**注意**：此为非原子操作，先将i从内存放入寄存器，寄存器自增，最后放回内存，共三步)，则读方法要加锁，如果有多个写线程则写方法要加锁。

## 4.13 线程池的作用

1. 避免线程频繁创建、销毁的开销。
2. 提高响应速度，不用等任务来了后再创建线程，可以直接分配一个已有线程。
3. 提高线程的可管理性。可通过线程池进行统一的分配、调优和监控。

## 4.14线程池的创建

1. 构造方法创建:ThreadPoolExecutor
2. 工具类Executors创建:
   1. FixedThreadPool:线程数量固定的线程池。
   2. CachedThreadPool：线程数可变的线程池。当没有空闲线程但有新任务来时，创建新线程。
   3. SingleThreadExecutor：单一线程的线程池。

## 4.15 ThreadPoolExecutor的参数

corePoolSize：核心线程数，指在**任务队列未满**的情况下的可同时运行的最大线程数

maximumPoolSize：最大线程数，当**队列满时**线程池的可同时运行的最大线程数

workQueue：等待队列，在当前线程数介于corePoolSize和maximumPoolsize之间时，新任务被放入队列中。

keepAliveTime：存活时间，当线程数超过核心线程数时，若无新任务提交，核心线程数外的线程等待keepAliveTime后被回收销毁。

unit：keepAliveTime的时间单位

threadFactory：创建新线程用到的

handler：饱和策略，在队列满、且已处于最大线程数的状态时，对于新任务采用的策略

### 4.15.1 饱和策略

1. AbortPolicy：抛出RejectedExecutionException来拒绝新任务
2. CallerRunsPolicy：调用执行自己的线程来运行任务。缺点：会降低新任务的提交速度。适用场景：可承受此延迟并不丢弃任何一个任务请求的状况。
3. DiscardPolicy：直接丢弃新任务。
4. DiscardOldestPolicy：丢弃最早的未处理的任务请求，将新任务放入队列。

## 4.16 线程池原理

![图解线程池实现原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png)



## 4.17 为什么进程切换比线程切换开销大？

​    **逻辑地址：**操作系统在页表中记录了逻辑地址到物理内存地址的映射关系，有了页表就可以将逻辑地址转换为物理内存地址了。每个进程都有自己的逻辑地址，进程内的所有线程共享进程的逻辑地址。

​    **进程切换与线程切换的最主要区别：**进程切换涉及到虚拟地址空间的切换而线程切换则不会。因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用TLB(Translation Lookaside Buffer)来缓存页地址，用来加速页表查找。当进程切换后页表也要进行切换，页表切换后TLB就失效了，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。

## 4.18 Java中如何正常终止线程？

好文章https://blog.csdn.net/xiewenfeng520/article/details/107301147/

1、使用interrupt（），我们一旦调用某个线程的 interrupt() 之后，这个线程的中断标记位就会被设置成 true。通过调用线程的isInterrupted()查看标记位，进行停止线程的操作。注意sleep期间，线程可感受到中断信号，抛出InterruptedException异常，同时清除中断信号，将中断标记位设置成 false。所以抛出 InterruptedException 异常之后，线程还在继续执行，`Thread.currentThread().isInterrupted()` 返回值仍然是 false，这种情况的应对方法：

1. run(）中使用用try/catch捕获InterruptedExceotion，并且在catch中手动中断当前线程。即调用interrupt()。
2. 此外，若run()中调用了子方法，该方法签名需抛出异常

2、使用volatile修饰的标志位

## 4.19 Java中主线程能否捕获子线程抛出的异常

可以捕获，给线程设置一个UncaughtExceptionHandler，可以确保在该线程出现异常时能通过回调UncaughtExceptionHandler接口的public void uncaughtException(Thread t, Throwable e) 方法来处理异常，这样的好处或者说目的是**可以在线程代码边界之外（Thread的run()方法之外），有一个地方能处理未捕获异常**。但是要特别明确的是：虽然是在回调方法中处理异常，但这个回调方法在执行时依然还在抛出异常的这个线程中！

## 4.20 多线程的数量设定

最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目
CPU核数为4核，一个任务线程cpu耗时为20ms，线程等待（网络IO、磁盘IO）耗时80ms，那最佳线程数目：( 80 + 20 )/20 * 4 = 20。也就是设置20个线程数最佳。

线程的等待时间越大，线程数就要设置越大

1、CPU密集型：操作内存处理的业务，一般线程数设置为：CPU核数 + 1 或者 CPU核数*2。核数为4的话，一般设置 5 或 8

2、IO密集型：文件操作，网络操作，数据库操作，一般线程设置为：cpu核数 / (1-0.9)，核数为4的话，一般设置 40



# 计网

## 体系结构、各层的作用

OSI七层模型：应用、表示、会话、传输、网络、数据链路、物理

TCP/IP四层模型：应用、传输、网际层、网络接口层

五层模型：应用、传输、网络、数据链路、物理

### 应用层

任务是通过应用进程间的交互完成特定网络应用，该层的协议定义了进程的交互和通信的规则。

常见协议：

DNS：是一个分布式数据库，提供域名与IP地址之间的转换服务。域名系统的层次结构为根域名、顶级域名、二级域名。大部分情况使用**UDP**进行传输。当**返回的响应超过512字节**（UDP 最大只支持 512 字节的数据）或进行**区域传送**（主域名服务器向辅助域名服务器传送变化的那部分数据）时使用**TCP**。

FTP：使用TCP进行连接，需要**控制连接**和**数据连接**来传送一个文件。

- **控制连接**用来传送客户端的命令、服务器的应答

- **数据连接**传送文件数据。

  根据数据连接是否是服务端主动建立，分为主动、被动模式：

  - 主动：服务端建立，服务端端口号20，客户端端口号随机但要大于1024
  - 被动：客户端建立，客户端端口号由它自己定义，服务端端口号随机

DHCP：配置IP地址、子网掩码、DNS服务器的IP地址。使用UDP协议工作。工作过程，

​		1、客户端广播Discover报文

​		2、DHCP服务器发送Offer报文给客户端，包含了所需信息

​		3、客户端会收到多个服务器提供的信息，选择其中一个，对其发送Request报文

​		4、服务器发送ACK报文，表示客户端可以使用其提供的信息了。

TELNET：远程登录协议

SMTP：电子邮件中的发送协议，只能发送ASCII码；POP3、IMAP：读取协议，区别在于旧版的POP3会删除服务端被读取后的邮件。

HTTP协议：用于从**万维网**（WWW:World Wide Web ）服务器传输**超文本**到**本地浏览器**的传送协议。

设备：计算机、服务器

### 传输层

给两台主机进程之间的通信 提供 通用的数据传输服务

常见协议：TCP、UDP

设备：防火墙

### 网络层

进行路由选择和转发，确保数据及时传送。

协议：

IPV4（32位地址）、IPV6（128位地址）

ARP：完成主机或路由器IP地址到MAC地址的映射。（为什么要进行该转换？数据链路层传送必须用MAC地址）。每个主机或路由器都有ARP高速缓存。

ICMP：网际控制报文协议，起差错报告和网络探询的作用。

- ICMP差错报文分为：终点不可达、参数问题、重定向、超时。

- ICMP询问报文：回送请求和报告报文、时间戳请求和回答报文。

  基于该协议的工具有ping和traceroute：ping侦测指定主机是否可达、traceroute查看当前主机到某地址经过多少跳路由。

IGMP：Internet组播管理协议。

路由选择协议，分为内部网关协议（RIP、OSPF）和外部网关协议（BGP）。RIP用距离向量算法更新路由表 、OSPF用链路状态路由算法更新路由表。

设备：路由器

### 数据链路层

封装成帧和差错控制。

设备：交换机

### 物理层

实现相邻节点间比特流的**透明传送**，尽可能屏蔽掉具体传输介质和物理设备的差异。

设备：集线器、网卡

## UDP和TCP的区别?

UDP：

1.无连接，时延、开销小

2.尽力交付，不保证数据可靠

3.面向报文段，即不会对应用层传下来的报文进行分段

4.首部8B

TCP：

1.面向连接，时延、开销大

2.传输的数据可靠有序、不丢不重（有拥塞控制、流量控制、序号、确认机制、重传机制）

3.面向字节流

4.全双工通信（只有面向连接的协议才有这个说法），收发双方都具有接收缓存和发送缓存

5.固定首部20B

### *****UDP、TCP的数据部分最大长度的区别？

MTU：最大传输单元，指数据链路层的帧的数据部分最大长度。

理论上，UDP数据报最大长度为65535字节（64KB），包含了首部 。

而实际上，UDP的数据部分最大长度受数据链路层的MTU的影响（不过最终是受Internet中路由器的MTU的限制，路由器的MTU标准为576B）

数据链路层中，**以太网帧**长度范围为64~1518B（头和尾共18B），数据部分长度范围为46~1500B，MTU为1500B.

故UDP的数据部分最大长度 = 1500B - 20B（IP数据报首部） - 8B（UDP首部）= 1472B   （或576-20-8 = 548）

同理，TCP的数据部分最大长度 = 1500B - 20B - 20B = 1460B（或576-20-20 = 536）

### 传输的应用层数据量能超过MTU吗？

UDP不能，要在**应用层**限制数据长度在548B之内，避免IP分片。

TCP能，因为在传输层的三次握手过程中互相告知MSS，避免IP分片。

当我们的UDP包中的数据多于MTU(1472)时，发送方的IP层需要分片fragmentation进行传输，而在接收方IP层则需要进行数据报重组，由于UDP是不可靠的传输协议，如果分片丢失导致重组失败，将导致UDP数据包被丢弃，所以在**应用层**要限制数据部分长度，不超过MTU。而且，Internet中路由器的MTU标准值为576B，所以UDP的数据长度最好设置成576-20-8=**548B以内**。

至于TCP， 可以超过，不用在应用层进行限制，因为在传输层的三次握手过程中，通信双方会相互告知MSS(最大报文段长度：用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度（不包括文段头），一般为MTU-20（IP首部长度）-20（TCP首部长度）)，每次发送的数据量不会超过MSS，保证了IP数据报长度不超过MTU，避免IP分片。

### IP分片定义和原理？

指对IP数据报进行分片。

在IP首部有4个字节是用于分片的，如下图所示。前16位是IP数据报的**标识**，同一个数据报的各个分片的标识是一样的，目的端会根据这个标识来判断IP分片是否属于同一个IP数据报。中间3位是**标志**位，其中有1位用来表示是否有更多的分片，如果是最后一个分片，该标志位为0，否则为1。后面13位表示分片在原始数据的**偏移**，这里的原始数据是IP层收到的传输的TCP或UDP数据，不包含IP首部。

![image-20201222204507575](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20201222204507575.png)

需要注意的，在分片的数据中，**传输层的首部**只会出现在第一个分片中，如下图所示。因为传输层的数据格式对IP层是透明的，传输层的首部只有在传输层才会有它的作用，IP层不知道也不需要保证在每个分片中都有传输层首部。所以，**在网络上传输的数据包是有可能没有传输层首部的**。

![img](https://bkimg.cdn.bcebos.com/pic/a8773912b31bb051dfce50073b7adab44aede033?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5)

### 为何要避免IP分片

在网络编程中，我们要避免出现IP分片，那么为什么要避免呢？原因是IP层是没有超时重传机制的，如果IP层对一个数据包进行了分片，只要有一个分片丢失了，只能依赖于传输层进行重传，结果是所有的分片都要重传一遍，这个代价有点大。由此可见，IP分片会大大降低传输层传送数据的成功率，所以我们要避免IP分片。

## UDP如何实现可靠传输

- UDP本身用校验和来校验整个数据报是否有错，错就丢弃。

- 依靠应用层来实现可靠传输:
  1. 实现确认机制
  2. 实现重传机制
  3. 实现滑动窗口机制

## TCP\UDP\IP报文格式

### TCP

![image-20210130152556457](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20210130152556457.png)

URG：紧急位，为1表明有高优先级数据，这些数据不用在缓存中等待；配合紧急指针（指出紧急数据的字节数）使用

ACK：确认位，为1时确认号有效，连接建立后所有报文段的ACK都为1。

PSH：推送位，为1时，接收方尽快交付数据，不用等缓存满。

SYN：同步位，=1，表明是连接请求、确认报文

RST：重置位，=1，说明连接存在错误，需释放连接，重新建立。

FIN：终止位， =1，表明是连接释放报文

窗口：该报文发送方的接收窗口，即报文接收方能发送的数据量。

### UDP

![image-20210130153635047](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20210130153635047.png)

UDP检验和：检验**整个UDP报文**是否出错。

### IP

![image-20210130155739652](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20210130155739652.png)

首部长度单位：4B

总长度单位：1B

片偏移单位：8B

标识：表示该IP分片属于哪一个数据报，同一数据报的IP分片有相同的标识

标志：代表该分片是否是最后一个分片，=1时，表示是。

片偏移：分片在原始数据的偏移，原始数据为TCP或UDP报文段，偏移是分片起始位置和报文段起始位置的距离。

协议：指示数据部分是什么协议，17 -> UDP, 6 -> TCP

首部检验和：检验**首部**是否出错

## TCP三次握手和四次挥手

## TCP 协议如何保证可靠传输，流量、拥塞控制

- 应用层数据会被分割成TCP认为合适长度的数据段，避免IP分片，具体地说，就是在三次连接的时候会相互告知MSS，避免IP数据报长度超过MTU，导致分片。

- 会为每个字节数据分配序号

- 采用校验和，检测数据在传输过程中是否发生变化，是的话，将丢弃该报文且不回送确认报文。

- 接收端会丢弃重复的数据

- 采用类似SR ARQ的机制，对数据进行累计确认和重传。与SR ARQ不同点为：1、确认号代表期望收到的报文段的首个字节数据的序号，而不是按序到达的最后一个分组的序号。2、不仅支持超时重传，还支持**快速重传**

- 使用滑动窗口机制实现流量控制。TCP首部中的窗口字段代表着窗口的大小。

  - **发送方**的发送窗口大小 = min(rwnd接收方的接收窗口，cwnd拥塞窗口)
  - rwnd 通过 **接收方**的确认报文段中的**窗口字段**告知给**发送方**
  - rwnd = 0时，**接收方**上传数据给应用层。**发送方**停止发送，并且启动计时器，到点后发送零窗口的探测报文给接收方，接收方回送确认报文并告知接收窗口大小。

- 进行拥塞控制。包括慢开始和拥塞避免算法、快重传和快恢复算法。

  - 慢开始和拥塞避免

    慢开始：拥塞窗口从1开始指数增长（2^RTT）cwnd=1，即cwnd为一个MSS（最大报文段长度）

    拥塞避免：cwnd到达阈值后，线性增长（+1），为一个发送出去的报文**设置的定时器超时且未收到确认，则认为网络拥塞**，新的阈值 = 当前cwnd/2，cwnd = 1，又进入慢开始状态。

  ![image-20210205151807667](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20210205151807667.png)

  - 快重传和快恢复（FRR）

    快重传：**收到3个冗余ACK就认为网络拥塞** ，进行快重传，重传接收方期望的报文段，并设置新的阈值 = cwnd / 2 。

    快恢复： cwnd = 新的阈值，执行拥塞避免算法。

  ![image-20210205151820461](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20210205151820461.png)



## ARQ协议（属于数据链路层、传输层协议）

- 停等ARQ

  收、发窗口大小都为1

  ![img](https://img-blog.csdn.net/20160313194700419)

- GBN ARQ

  收、发窗口>1

  ![img](https://img-blog.csdn.net/20160313194725494)

  若某报文段（比如2）未被正确接收，重发**从该报文段开始的所有报文段**。

  接收方只会按序接收报文段，遇到乱序的报文段会丢弃，回送的ack=按序到达的最后一个报文段的序号（1）

- SR ARQ

  若某报文段未被正确接收，重发**该报文段**。

  接收方会接收乱序的报文段，回送的ack=当前接收到的报文段序号。最终会进行重排序，存在延迟和突发数据输出问题。

- TCP中

  若某报文段未被正确接收，重发**该报文段**。

  接收方会接收乱序的报文段，回送的ack=期望收到的报文段数据部分首个字节的序号。

### GBN、SR、TCP区别

![image-20210205155509663](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20210205155509663.png)

## TCP粘包

### 什么是TCP粘包？

客户端连续发送数据包时，服务端接收到的数据出现数据包粘在一起的情况。

### 有UDP粘包吗？

没有。UDP首部用了16个bit来指示UDP报文的长度，能很好的将不同的数据报文区分开。而TCP是基于字节流的，数据没有明确的界限，可能会发生粘包、拆包现象 。

### 粘包拆包表现形式？

1、接收端正常得到两个数据包。即没有发生粘包拆包现象

2、接收端收到一个数据包，这个包中包含了发送端发送的两个数据包信息。出现了粘包现象。

3、接收端收到两个数据包，一个数据包是不完整的，缺失的数据在另一个数据包里。出现了拆包、粘包现象。

### 发生的原因？

1、要发送的数据大于TCP发送缓冲区剩余空间大小，会发生拆包

2、要发送的数据大于MSS最大报文长度，TCP在传输前进行拆包

3、要发送的数据小于 TCP发送缓冲区的大小，发生粘包

4、接收端没有及时读取 接收缓冲区中的数据，发生粘包

概括来说，主要原因是接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。

### 解决方法

1、给每个数据包 添加包首部，包含数据包的长度信息，接收端通过读取该信息，可知道每个数据包的长度。

2、将每个数据包封装成固定长度，不足补0，这样接收端每次读取固定长度的数据即可。

3、在包之间设置边界，比如添加特殊符号，接收端通过边界拆分数据包。

## 浏览器输入url后发生的事儿

### DHCP配置主机信息

如果主机最开始没有ip地址、子网掩码、DNS服务器IP地址，首先会通过DHCP来获取。

### 然后。。。

<img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/url%E8%BE%93%E5%85%A5%E5%88%B0%E5%B1%95%E7%A4%BA%E5%87%BA%E6%9D%A5%E7%9A%84%E8%BF%87%E7%A8%8B.jpg" alt="img" style="zoom:50%;" />

1、2步中间要建立TCP连接。

## DNS基本流程

DNS有两种查询方式，递归查询和迭代查询。

迭代 查询：浏览器向本地域名服务器查询ip地址，若没有找到，本地域名服务器向根域名服务器发送请求，进行查询，若也不存在，本地域名服务器向顶级域名服务器发送请求，以此类推。直到最后本地域名服务器获得ip地址，缓存到本地。

递归查询：本地域名服务器-->根域名-->顶级-->二级

### DNS的优化 

#### DNS缓存

浏览器缓存、系统缓存、路由器缓存、IPS服务器缓存、根、顶级、二级域名服务器缓存。

#### DNS负载均衡

根据每台机器的负载量、离用户地理位置的距离等，决定返回合适的机器的ip给用户。

## get和post的区别

HTTP只是个行为准则，TCP是GET\POST实现的基本，所以GET/POST本质都是TCP连接，能做的事情是一样的，没有区别。

由于HTTP的规定和浏览器/服务器的限制，导致两者在应用过程中出现不同。区别包括：GET语义为请求获取指定的资源，此方法是安全（对服务端来说，因为不会改变服务端状态）、幂等、可缓存的，报文主体没有语义，参数只能以ASCII码出现在url中；POST语义是根据报文主体对特定资源做出处理，不安全、不幂等、不可缓存。

## cookie和session的区别

|          | cookie                                                       | session                                                  |
| -------- | ------------------------------------------------------------ | -------------------------------------------------------- |
| 存放位置 | 浏览器                                                       | 服务器                                                   |
| 安全性   | 不够安全，容易被恶意查看                                     | 较安全                                                   |
| 性能上   | 能减轻服务器压力                                             | 把信息都存储在服务器，会有很大的开销，所以不建议这样做。 |
| 数据长度 | 单个cookie保存的数据不超过4K，很多浏览器会限制一个站点保存的cookie数量 |                                                          |
| 数据类型 | 只能存ASCII码字符串                                          | 可以存储任何类型的数据                                   |

## 服务器如何知道客户端已发送完毕？

如果是短连接，可以通过是否关闭了连接来判断。

如果是长连接：

​	1. 先把header直到\r\n\r\n整个接收下来，进行解析，看content-length字段是否存在（即获取报文首部，查看有无content-length字段）。

​	2、若存在，则从header的末尾开始读取Content-length个字节

​	3、若不存在，如果Transfer-Encoding字段为chunked，一直读到\r\n0\r\n\r\n则结束。（具体地说，这是分块传输编码方式，在每一块传输的数据前都会有一个16进制数表示这一块数据的长度。）

​	4、若无Transefer-Encoding字段，说明已经发送完毕。

## HTTP-》HTTPS

|           | HTTP                                                         | HTTPS（=SSL+HTTP）                                           |
| --------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 特点/问题 | 1、使用明文通信，会被窃听 2、不验证通信方身份，身份会遭伪装 3、无法验证报文完整性，内容遭篡改 | 1、加密（对称+非对称，防窃听）2、认证（证书，防伪装）3、完整性保护（SSL的报文摘要功能，防篡改） |

### 加密

1、使用非对称密钥加密方法，传输密钥，保证安全性。（换个说法，就是用接受方发来的公钥，对密钥（对称密钥加密方法所需的）进行加密，传送给接收方，接收方再用私钥解密）

2、获取到密钥后，使用对称密钥加密方法进行通信，保证效率。

### 认证

采用**证书**对通信方进行认证，需要通过客户端和服务端都**信任的第三方**，即**CA**(数字证书认证机构)。

认证过程：

1、服务器将**公钥**交给CA进行认证，CA判明申请者的身份后，用自己的私钥对服务器提供的公钥做**数字签名**，然后将签名、服务器公钥和**公钥证书**绑定。

2、进行HTTPS通信时，服务器（也可能是黑客伪装的）将**证书**给客户端，客户端使用内嵌在浏览器中的CA**公钥**对证书中的**签名**进行**解密**，并将解密结果与证书中的服务器公钥比对，若一致，说明该公钥确实是服务器的。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/2017-06-11-ca.png)

### 完整性保护

SSL提供**报文摘要功能**进行完整性保护。

HTTPS的报文摘要功能结合了加密和认证，所以安全。

## http1.0、1.1、2.0区别

### HTTP1.0

1、默认使用短连接，每次连接都要重新建立一次连接，开销大。

2、使用header里的if-modified-since和expires作为缓存判断的标准。

3、不支持传输对象的一部分内容。也不支持断点续传。

### HTTP1.1

1、默认使用长连接，connection字段为keep-alive，有流水线和非流水线方式，（流水线是客户端在接收到HTTP的响应报文前就能接着发送新的请求报文，非流水线需要收到响应报文后才能接着发送。）

2、引入了更多的缓存控制策略，如if-unmodified-since，if-match，if-none-match。

3、在header中引入range字段，允许只请求资源的一部分，返回的状态码是206（partial content）；支持断点续传。

4、相比1.0新增24个错误状态响应码，409（conflict）代表请求与服务端目标资源的当前状态冲突，最可能发生在PUT请求的响应中；410（Gone）代表服务器上的某个资源被永久删除。

### HTTP2.0

1、采用二进制格式解析

2、多路复用，多个请求可共享一个连接

3、支持首部压缩

4、有服务端推送功能，将与服务端请求的资源相关的内容一并返回



http2.0的多路复用和http1.1长连接复用的区别：

HTTP2多个请求可同时在一个连接上**并行执行**

### HTTPS缺点

需要加密解密，速度慢，开销大

购买证书要花钱

## HTTP首部

请求特有：请求首部字段（range 实体的字节范围请求、accpet可处理的媒体类型、accept-charset优先的字符集、accept-encoding、accept-language、if-match比较实体标记、if-modified-since比较资源的更新时间、if-none-match, if-unmodified-since）

响应特有：响应首部字段（accept-ranges 是否接收字节范围请求、age推算资源创建经过时间、location令客户端重定向到指定URL）

两者共有：通用首部字段、实体首部字段(content-range 实体主体位置范围、content-length实体主体大小、content-encoding、content-language、content-type)

## HTTP状态码

### 1XX 消息状态码

100：continue， 表明目前为止正常，客户端可以继续发送请求或忽略这个请求。

### 2XX成功状态码

200： OK， 请求成功处理

204：No content， 请求成功处理，但返回的报文响应不包含主体部分，一般用在，客户端向服务端发送请求，但不需要返回数据时使用。

206：partial content，表示客户端进行了范围请求，响应报文包含由**content-range**指定范围内的实体内容。

### 3XX重定向

301：moved permanently，**永久**重定向

302：found，**临时**重定向

303：see other， 同302， 但是要求用客户端**用GET**方法请求资源。

（HTTP规定301、302状态下，不能把post改成get，但浏览器都会把301、302、303状态下的post改成get）

304：not modified， 如果请求报文首部中包含如 if-match，if-modified-since等条件，不被满足时，返回304.

307：临时重定向，与302类似，但不同在于，307要求**不将**post改成get。

### 4XX客户端错误

400：bad request, **请求报文**中有**语法错误**

401：unauthorized， 表示用户认证失败，出现的场景：1、服务端要求token，客户端没有发送 2、客户端发送了token，但该token在服务端已经过期了。（总之，token失效或没有传递）。

403：forbidden， 请求**被拒绝**

404：not found ，请求的资源未在服务器上找到

### 5XX服务端错误

500，internal server error， 服务器执行请求时出错

502，bad gateway，作为网关或代理工作的服务器尝试执行请求时，从上游服务器收到无效的响应。

503，service unavailable，服务器处于超负载or停机维护状态，无法处理请求。

## HTTP缓存

浏览器缓存的一种。

浏览器缓存分为：强缓存、协商缓存。

浏览器加载页面的流程：

1. 浏览器先根据这个资源的http**头信息**来判断是否命中**强缓存**。如果**命中**则**直接加载**缓存中的资源，并不会将请求发送到服务器。
2. 如果**未命中**强缓存，则浏览器会将资源加载**请求发送**到服务器。服务器根据http头信息中的Last-Modify/If-Modify-Since或Etag/If-None-Match来判断**是否命中协商缓存**。如果命中，则http返回码为304，浏览器从缓存中加载资源。
3. 如果未命中协商缓存，则服务器会将完整的资源返回给浏览器，浏览器加载新资源，并更新缓存。





# 操作系统

## 什么是操作系统？

1、管理计算机硬件和软件资源的计算机程序

2、为用户提供与系统交互的操作界面

3、分为内核和外壳，**外壳**是围绕内核的应用程序，**内核**负责管理进程、内存、设备驱动程序、文件、网络系统等。

### 用户态和内核态

#### 区别

是CPU的两种运行状态。

用户态 ：运行用户程序，只能受限地访问内存，不允许访问外围设备。

内核态：运行操作系统程序，可以访问计算机的任何资源。

#### 指令划分

特权指令：只能由操作系统使用，如修改PSW（程序状态字）

非特权指令：用户程序也可使用，如算术运算、陷入指令（使用户程序从用户态陷入内核态）

#### CPU状态间的转换

用户态->内核态：唯一途径是通过中断、异常（如缺页异常）、**陷入指令**（系统调用时会用到）

![img](https://kityminder-img.gz.bcebos.com/a0b5705e8596036c1881eb8cad55909930d243ca)

内核态->用户态：设置程序状态字(PSW)

### 系统调用

是操作系统提供给程序使用的**接口**，通过**系统调用**向系统发出请求，能使系统合理协调管理各请求，保证系统稳定性和安全性。

**处理**系统调用在**核心态**下进行，**发起**系统调用请求在**用户态**下进行。

## 死锁相关

死锁：各进程互相等待资源，导致各进程阻塞，无法继续推进。

产生原因（系统资源不足、资源分配不当、进程间推进顺序不合适）：

​	1.竞争**不可剥夺资源**（打印机、磁带机）或**临时资源**（硬件中断、信号、消息等）

​	2.进程间推进顺序非法，比如两个进程P1,P2都需要资源R1和资源R2，现在先使P1获得R1，P2获得R2，接下去就需要请求对方拥有的资源，这个推进顺序就是非法的。

### 四个必要条件

​	互斥条件、不剥夺条件、循环等待条件、请求与保持条件

### 预防死锁

​	破坏四个条件中的其中一个：

​	1、互斥条件不好破坏

​	2、对于不剥夺条件，可以使操作系统协助剥夺or申请的资源得不到满足时，立即释放拥有的所有资源。

​	3、对于循环等待条件，可以给资源编号，按从小到大的顺序申请资源。

​	4、对于请求和保持，在运行前分配好所有需要的资源，之后一直保持。

### 避免死锁

​	银行家算法，避免系统进入不安全状态。

​	步骤：

​	1、检查此次资源请求是否超过了之前进程声明的最大需求数

​	2、检查剩余资源能否满足这次请求

​	3、试探着分配

​	4、采用安全性算法检查此次分配是否会使系统进入不安全状态

​		1）检查这次分配能否满足某个进程的最大需求，若可以，将改进程加入安全序列，回收其持有的资源

​		2）重复进行，看能否将所有进程都加入安全序列。

​	5、若安全性算法无法将所有进程加入安全序列说明此次分配不安全，不进行分配 。

## 进程和线程

### 区别

1、进程是资源分配的基本单位，线程是处理机调度的基本单位 

2、进程有独立的地址空间，而同一进程的线程共享数据和地址空间。

3、线程间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程需要通过**IPC**进行通信，资源开销大。

4、多进程更 加健壮，一个进程死掉不会影响另一个进程，而多线程程序中，一个线程挂掉，整个进程也挂掉。

### 进程的状态及转换

1、创建态：进程正被创建，尚未就绪。

2、就绪态：进程获得了除处理器之外的所有资源，等得到处理器分配的时间片后即可运行。

3、运行态：进程正在处理器上运行

4、阻塞态：进程用“系统调用”的方式，申请某种系统资源or等待某个事件发生

5、终止态：进程结束退出运行（正常结束或中断结束）。

![img](https://kityminder-img.gz.bcebos.com/a089c278fbac2cab857e597a5e81d6f48a19240e)

### 何为**进程间通信**（IPC）？

每个进程有不同的用户地址空间 ，无法看到各自的变量，需要在内核中开辟缓冲区，实现数据的交换，此为**进程间通信**。

进程间通信：

1、匿名管道：

- 用于**父子、兄弟**进程间的通信，面向字节流的服务

- **半双工**，数据单方向流动; 需要双方通信时建立两个管道

- 管道构成一种独立的文件系统，只存在**内存**中。实质是一个**内核缓冲区**，进程以**先进先出**的方式存取数据。

- 管道进行通信的步骤：拿父子进程通信为例：

  1、父进程创建管道，得到两个文件描述符pipefd[0]和pipefd[1]，分别指向管道的读端和写端。

  2、利用fork函数创建子进程，则子进程也得到两个文件描述符指向管道两端。

  3、父进程关闭读端，子进程关闭写端，则此时父可写，子可读，实现半双工通信。如果想要同时父进程读，子进程写，需要打开另外一个通道。

  兄弟进程间的通信是由父进程fork两次，把文件描述符给两个子进程，然后相同的步骤，使两进程进行通信。

2、有名管道

- **任意进程**间的通信，遵循FIFO，半双工，面向字节流。
- 以**磁盘文件**形式存在
- 管道名（文件描述符）存在文件系统中，内容存在内存中。

3、消息队列

- 保存在内核中的消息链表，有**特定格式**，发送数据时会分成一个个独立的数据单元，也叫消息体。支持FIFO和**随机查询**、可以按消息的类型读取。
- 消息队列随内核持续，只有在**内核重启**或**显式地删除**时，才会真正被删除。
- 与管道不同，某个进程往消息队列写入消息前，不需要另一个进程在队列上等待。
- 存在用户态和内核态之间的数据拷贝开销。

4、信号

- 对于**异常情况**下的工作模式，使用信号通知进程。
- 唯一的异步通信机制，因为可在任何时候发送信号给进程，进程对信号的处理方式有三种 ：1、执行默认操作 2、忽略信号 3、捕捉信号

5、信号量

- 一个整型计数器，用于实现**进程同步与互斥**。计数器在内核中实现，因为信号量的PV操作需要是原子操作，来保证正确性。 

- 信号量的数据结构为一个值和指针，指针指向等待该信号量的下一个进程。

- 信号量为1，互斥信号量；为0， 同步信号量

- P（S）：①将信号量S的值减1，即S=S-1；

  ​          ②如果S>=0，则该进程继续执行；否则该进程置为等待状态，排入等待队列。

  V（S）：①将信号量S的值加1，即S=S+1；

  ​          ②如果S>0，则该进程继续执行；否则释放队列中第一个等待信号量的进程。

6、共享内存

- 多个进程能直接读取同一块内存空间，**最快**的进程间通信方式。
- 内核专门留出一块空间，可由需要访问的进程将其**映射到自己的私有地址空间**，进而**直接读写**，而不需要拷贝（消息队列需要）。
- 由于多个进程共享，需要同步机制来同步及互斥（信号量）。

7、套接字

- 上述几种用于同台主机上的进程通信，套接字除此之外，还能用于跨网络的**不同主机间的进程通信**。

- 套接字的特性由三个属性决定，域、端口号、协议类型：

  **域**指定通信中使用的网络介质，AF_INIT指的是Internet网络（AF_INIT->IPV4, AF_INET6->IPV6），AF_UNIX表示文件系统。

  **端口号**，端口是一个信息缓冲区，用于保留socket中的输入/输出信息。端口号是16位无符号整数。

  **协议类型**有三种，字节流套接字（SOCK_STREAM）、数据报套接字（SOCK_DGRAM）和原始套接字。

- 基于创建socket的类型不同，可分为三种通信方式：1、基于TCP协议的通信方式 2、基于UDP协议的通信方式  3、本地进程间通信方式

#### Socket通信基本流程

![img](https://upload-images.jianshu.io/upload_images/1281379-2575b81bbab6b67b.png?imageMogr2/auto-orient/strip|imageView2/2/w/437/format/webp)

步骤：

​	1、服务器进程创建套接字

​	2、服务器进程给套接字绑定监听端口

​	3、系统调用**listen**设置监听队列，用来存放客户端的连接请求

​	4、服务端通过系统调用**accept**接收客户端请求。会创建新套接字，专门用来和这个客户端通信，原先的套接字则用来继续处理其他客户的连接。

### 线程间通信（同步）

1.互斥量：互斥对象机制，只有拥有互斥对象的线程才有访问资源的权限。synchronized和lock都是这种机制

2.信号量：允许多个线程访问同一资源，线程数不能超过资源数。

3.事件：wait/notify，采用通知操作保持多线程同步。



### 调度的三层次

作业调度：从**后备队列**（位于外存）中选择作业调入内存，并为其创建进程（建立PCB）

内存调度：从**挂起队列**（位于内存，存放被挂起进程的PCB，根据其中的位置信息能找到存放在外存中的进程并调入）中选择进程（位于外存）将其调入内存

进程调度（发生频率最高）：从**就绪队列**（内存）中选择进程，为其分配处理机（CPU）

<img src="https://kityminder-img.gz.bcebos.com/a6b4dc7354d35d12c44521fc6038c9933fe47163" alt="img" style="zoom: 67%;" />

#### 进程的调度算法

1、FCFS先到先服务：从就绪队列中选择**最先进入**的进程（即**等待时间**最长的），并为之分配处理机

2、SJF短作业优先（SPF短进程优先）：**要求服务时间**最短的作业/进程先得到服务

3、高响应比优先：响应比 =（等待时间+要求服务时间）/要求服务时间

![img](https://kityminder-img.gz.bcebos.com/4f48a6fc586939a70dab7a5f1d3a6bd48cffcde9)

3、时间片轮转：**只能用于进程**，按进程进入就绪队列的顺序，分配时间片，若未在该时间片内运行完，则重新放到队列尾排队等待时间片。**抢占式**的，时钟发出**时钟中断**通知CPU时间片已到。

​	  时间片太大，退化成FCFS；太小，频繁的切换进程，耗费时间。

4、优先级调度： 选择优先级高先处理。

5、多级反馈队列：**只能用于进程**，

​	  1）设置多级就绪队列，队列**优先级从高到低**， **时间片从小到大**

​	  2）**新进程**先进入**第一级**队列，按FCFS分配时间片，时间片结束，进程未完结，放入**下一级**队列队尾，若已经是**最后一级**队列，则放回**该队列**队尾。

​	  3）只有当第K级队列为空时，才为K+1级**队头**的进程分配时间片。

​		注意：正常运行完时间片，进入下一级队列；被抢占了处理机，重新放回所属队列的队尾。

![img](https://kityminder-img.gz.bcebos.com/22045669075b876415c70a184b646e34e6e6a9ec)

调度算法总结：只有SPF、时间片轮转和多级反馈队列是**进程独有**的，SJF是**作业独有**，FCFS、高响应比优先、优先级调度两者都适用。

## 内存管理机制

### 连续分配管理方式

​	![img](https://kityminder-img.gz.bcebos.com/89e836198edfb7d3bffa65a6958555e3b3691cbe)

### 非连续分配管理方式

#### 分页存储管理

思想：将进程分页，各页面可离散地放到各内存块中。

![img](https://kityminder-img.gz.bcebos.com/3c982361979cb2f4c1406cfa8c9e153066a8d60b)

##### 快表

存放在高速的存储器中，记录最近使用过的**页表项**，可以减少访存的次数，加速查找，提高指令执行速度。

![img](https://kityminder-img.gz.bcebos.com/2011f00231d56e7a5612c23f28a4dd72585cb564)

##### 两级页表

解决单级页表存在的问题：1、所有页表必须连续存放，占用大量空间 2、整个页表常驻内存。

![img](https://kityminder-img.gz.bcebos.com/4dc7d3e3cf1af8def6df9acedc8fb3f330af0c7a)

#### 分段存储管理

思想：将地址空间按程序自身的逻辑关系划分成若干个段，每段从0开始编址。

![img](https://kityminder-img.gz.bcebos.com/188a20bb1f937c99669291f973b11514401d6792)

##### 分页和分段的区别

共同点：

​	1、都是为了提高内存利用率，减少内存碎片。

​	2、都是不连续内存分配方式，段之间、页之间不连续，但每个段和页内是连续的。

不同点：

​	0、页的大小固定，由操作系统决定；段的大小不固定，取决于运行的程序。

​	1、分页对用户不可见、分段可见

​	2、分页的地址空间一维，分段的地址空间二维

​	3、分段更容易实现信息的共享和保护

![img](https://kityminder-img.gz.bcebos.com/c149ec3df3b209a089a8cd011708e27575e105aa)

#### 段页式存储管理

思想：先分段，再对每段分页。访存次数会达到3次噢，段表、页表、内存单元。

![img](https://kityminder-img.gz.bcebos.com/df219a2c04eb02ba426ca28a4d2804872a5ba06c)



## 虚拟（逻辑）地址 v.s. 物理地址

物理地址：内存单元真正的地址

虚拟地址：由操作系统决定的地址，通过**MMU**，映射到物理地址。

#### MMU内存管理单元

现代处理器采用**虚拟寻址**的寻址方式。CPU中的MMU将虚拟地址翻译成物理地址，进而访问到物理内存。

#### 为何需要虚拟地址？

##### 直接访问物理地址存在的问题

​	1、进程地址空间不隔离。由于进程都是直接访问物理地址，所以可以修改别的进程的内存数据，造成影响。

​	2、内存使用效率低。当有进程运行的情况下，又运行了新的进程，但此时内存不足，就会将已运行的进程暂时拷贝到硬盘中，释放空间给新的进程用，**大量的数据装入装出**，导致效率低下。

​	3、程序运行的地址不确定，会**随机分配**可用的连续内存给程序用。

##### 使用虚拟地址的好处

​	1、只要处理好虚拟地址到物理地址的映射，就能使不同进程使用的虚拟地址彼此隔离，一个进程中的代码就无法更改另一个进程使用的物理内存

​	2、可以使用虚拟地址访问物理内存中不相邻的内存块。

​	3、可以使用虚拟地址来从逻辑上扩充内存容量，也就是**虚拟内存**技术。



## 虚拟内存

定义：程序不用全部装入内存即可运行，运行时根据需要动态地从外存中调入数据，若内存不足，还需换出一部分数据，从逻辑上扩充了内存的容量。

特征：

1、多次性：不需要一次性将作业数据全装入内存，允许分成多次装入。

2、对换性：数据不需要在作业运行过程中常驻内存，允许将作业数据换入换出。

3、虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。

### 虚拟内存的理论支持

#### 局部性原理

时间局部性原理：现在访问的指令、数据，可能在不久后会被再次访问

空间局部性原理：现在访问的内存单元周围的内存空间，可能在不久后会被访问。

### 虚拟内存的技术实现

虚拟内存基于**离散分配**的内存管理方式实现，分为**请求分页**存储管理、**请求分段**存储管理和**请求段页式**存储管理。

#### 请求分页存储管理和基本分页存储管理区别

**请求分页存储管理**是在**基本分页存储管理**的基础上，添加了**请求调页**功能和**页面置换**功能。

1、页表方面，在基本分页的基础上添加了几个表项：

​	1）状态位：该页是否在内存中

​	2）访问字段：记录被访问的次数or上次被访问的时间，给置换算法做参考

​	3）修改位：表示页面调入内存后是否被修改过，若修改过，在置换时需要重新写入外存。

​	4）外存地址：页面在外存的存放地址。

 2、具有缺页中断机制：

​	![image-20201026163206203](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20201026163206203.png)

3、地址变换机制方面多了这几步：

​	1）找到页表项时需要通过**状态位**检查页面是否在内存中

​	2）若不存在，则触发缺页中断，请求调页

​	3）内存如果不够，还会换出页面

​	4）页面调入内存后，需要修改状态位

### 页面置换算法

OPT ：优先淘汰最长时间内不会被访问的页面。 理论上的，实际无法实现。

FIFO：优先淘汰先进入内存的页面。实现简单、性能差、belady异常。

（何为belady异常？ 内存中的页面数上限增多，缺页率反而升高的现象）

LRU：优先淘汰最近最久没访问的页面，性能好，开销大。

LFU：优先淘汰最少使用的页面，开销大（记录所有数据的访问记录，内存消耗高；基于引用计数排序，性能消耗高）

CLOCK：

最初要经过一轮遍历，每次遍历到一个节点发现访问位=1的，将该标记位置为0，然后遍历下一个页面，一轮遍历完后，发现没有可以被逐出的页面，则进行下一轮遍历，这次遍历之后发现原先1号页面的**标记位u=0，则将该页面逐出，置换**为页面5，并将指针指向下一个页面。

改进型CLOCK：在CLOCK基础上，考虑修改位的状态。

## 磁盘结构

盘面：一个磁盘有多个盘面

磁道：**盘面**上的环形带状区域，一个盘面有多磁道

扇区：**磁道**上的一段弧，一磁道有多扇区，**最小的物理存储单位**。

磁头：负责与**盘面**的读写操作。

制动手臂：负责移动磁头

主轴：旋转整个盘面

## 磁盘调度算法

读写一个磁盘的时间包括：

1、旋转时间：主轴转盘面

2、寻道时间（最耗时）：制动手臂移动磁头，使其移动到适合的磁道

3、数据传输时间

### FCFS

按磁盘请求顺序进行调度

### 最短寻道时间优先

优先调度**与当前磁道距离最近**的磁道，存在饥饿问题。

### 电梯算法

往一个方向进行磁盘调度，该方向磁盘请求处理完后，掉转方向。无饥饿问题。

## 僵尸进程和孤儿进程

#### 僵尸进程

子进程在父进程没有调用wait方法和waitpid方法的情况下退出，这样的子进程就是僵尸进程，子进程的PCB没有被释放。

解决方法：

1、杀死父进程，这样能使僵尸进程变成孤儿进程，由系统回收。暴力的方法，不可取。

2、父进程调用wait函数，回收僵尸子进程。

#### 孤儿进程

父进程退出，而其子进程还在运行，那么这些进程会成为孤儿进程，将被init进程（pid=1的进程）收养，会负责回收孤儿进程，不像僵尸进程会占用ID。



## 各种IO模型

**IO操作**两个阶段：1、等待数据  2、拷贝数据

#### 阻塞IO模型

​	用户线程发出IO请求，用户线程处于阻塞状态（交出CPU），内核查看数据的就绪情况，就绪，内核将数据拷贝到用户空间 ，并返回结果给用户线程，用户线程解除阻塞。 **询问/拷贝都阻塞**。

#### 非阻塞IO模型

​	**用户线程**不断询问内核数据是否就绪（不交出CPU，非阻塞），就绪后内核将数据拷贝到用户空间。**询问非阻塞，拷贝阻塞。**

#### 多路复用IO模型

​	**内核**轮询socket，数据就绪后，内核将数据从内核空间拷贝到用户空间。**拷贝/轮询过程都是阻塞的**。

##### 	三种实现方式：select、poll、epoll的区别

​	每次调用select和poll时，都要把fd集合从用户态拷贝到内核态，内核会进行**轮询**，判断数据是否就绪，将就绪的fd返回给select，select通知系统调用，将数据从内核空间拷贝到用户空间。其中，select用数组描述fd集合，最大连接数为1024/2048；poll用链表描述，无连接数限制。

​	epoll在内核中维护一个事件表，使用epoll_ctl函数往其中注册事件，将fd拷贝到内核态中。之后每次epoll_wait无需重新拷贝。epoll采用**回调**方式检测就绪事件（事件和fd关联，事件就绪即对应fd就绪），当就绪时，触发回调函数，将就绪fd放入就绪队列，epoll_wait去查看这个队列，将数据从内核态拷贝到用户态。无连接数限制，1G的内存上能监听10W个端口。

![img](https://upload-images.jianshu.io/upload_images/4324552-3092b760d33aeea6.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

epoll有epolllt和epollet两种触发模式，区别：

​	**LT模式**下，只要这个fd还有数据可读，每次epoll_wait都会返回这个事件，提醒用户去操作；**ET模式**下，只通知一次，无论是否还有数据，直到该fd上出现第二次读写事件时才会再次通知 。

#### 信号驱动IO模型

​	用户线程发起请求，内核数据就绪时发送信号给用户线程，**用户线程调用IO读写**操作。**等待非阻塞， 拷贝阻塞。**

#### 异步IO模型

​	用户线程发起IO请求后立即返回，做其他事情。内核等待数据就绪后，拷贝到用户线程。**IO操作的两个阶段都不会阻塞用户线程。**

![image-20200901143616337](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200901143616337.png)



#### 同步异步区别

同步：发出一个调用请求时，在没有得到结果之前，不会返回。

异步：发出调用请求后立即返回，做其他事情，有结果后会得到通知的。

#### BIO、NIO、AIO区别

BIO：同步阻塞IO模式，数据的读取、写入必须阻塞在一个线程内等待其完成；面向字节流。

NIO：同步非阻塞的IO模式，支持面向缓冲、基于通道的IO操作方法，实现了IO多路复用中的reactor模型，一个**线程**使用一个**选择器**通过**轮询**的方式去监听多个通道上的事件，从而让一个线程可以处理多个事件。

​		通过配置监听的通道为非阻塞，那么当通道上的IO事件还未到达时，就不会进入阻塞状态一直等待，而是会轮询其他channel，找到IO事件到达的channel执行。注意：只有套接字channel能配置成非阻塞。

AIO：异步非阻塞的IO模式，基于事件和回调机制，当用户线程发出调用请求后，可以继续做其他事，内核完成IO操作后，返回信号通知用户线程，进行后续操作。

# MYSQL	

## 关系型和非关系型数据库的区别

### 关系型

数据结构是表，由二维表及其之间的联系所组成的数据组织。

优点：

1、**易于维护**，都是表结构，格式一致

2、**使用方便**，SQL语言通用

3、**支持复杂查询**

缺点：

1、**读写性能较差**

2、**固定的表结构、灵活性差**

3、高并发读写需求下，**磁盘IO是很大瓶颈**。

### 非关系型

严格来说不是一种数据库，是一种数据结构化存储方法的集合，可以是键值对（如redis）或文档（如MongoDb）等。

优点：
1、**格式灵活**：存储数据的格式**可以是key/value形式、文档形式、图片形式等等**，使用灵活，应用场景广泛，**而关系型数据库则只支持基础类型**。
2、**速度快**：nosql可以使用硬盘或者内存作为载体，而关系型数据库只能使用硬盘；
3、**成本低**：nosql数据库**部署简单**，**基本都是开源软件**。

缺点：
1、不提供sql支持，**学习和使用成本较高**；
2、**数据结构相对复杂**，复杂查询方面稍欠。

## 事务的特性

### 原子性

事务是不可分割的最小单元，其中的操作要么都执行成功，要么都失败回滚。回滚使用undo log实现，undo log中记录事务执行的所有**修改操作**，回滚时**反向执行**即可。

### 一致性

**这里的一致性是指系统从一个正确的状态,迁移到另一个正确的状态.正确的状态指当前的状态满足预定的约束就叫做正确的状态.而事务具备ACID里C的特性是说通过事务的AID来保证我们的一致性.**   这个约束是应用层的约束。

### 隔离性

一个事务所作的修改在提交之前，其他事务不可见。

### 持久性

一旦事务被提交，所有修改都会永久保存到数据库中，即使系统发生崩溃，事务的执行结果也不能丢失。发生崩溃后可以用redo log恢复数据，redo log记录被修改后的**数据**。

### undolog 、redolog、binlog区别

undolog和binlog都是逻辑日志，记录修改语句；redolog是物理日志，记录被修改后的数据。

更详细地：

1、binlog，server层公用的日志模块，主要做的是mysql功能层面上的事情；
2、redolog，引擎层独有的日志模块，主要处理引擎相关的事情；
两者的区别如下：
1、binlog是server层公共的日志模块，主要作用是归档，用于主从同步和数据库基于时间点的还原；而redolog是InnoDb引擎独有的，用于实现crash-safe的能力，即数据库崩溃重启后能保证事务的完整性，已提交的数据不会丢失，未提交完整的数据就借助undolog回滚。
2、binlog是**逻辑日志**，记录的是执行的sql语句或者更新前后的数据行；而redolog是**物理日志**，记录了在某个数据页中做了哪些修改；
3、binlog是**追加写**日志，当日志文件写到一定大小之后会切换到下一个，而redolog是基于固定空间大小的日志文件**循环写**日志；

## 并发事务带来的问题

### 丢失修改

两个先后读取到了数据，接着进行修改，那么第一次的修改结果会被第二次修改结果覆盖，故第一次的修改丢失。

### 脏读

一个事务对数据进行了修改但未提交，此时另一个事务访问并使用了该数据，这就是脏读。

### 不可重复读

在一个事务对数据的两次读操作中间，另一个事务访问并修改了该数据，这就导致第一个事务两次读结果不同。

### 幻读

在一个事务对某范围内的数据的两次读操作中间，另一个事务插入了一些数据，这就导致第一个事务两次读出来的数据量不同。

### 解决方法

这些问题主要是**隔离性**破坏所导致的。

采用并发控制来保证隔离性，即**加锁**or直接使用**隔离级别**。

## 封锁

### 锁粒度

#### 行锁、表锁

锁的原则：尽可能只锁需要修改的数据。因为锁定的数据量小，发生竞争的可能性小，系统的并发度高。

但是，锁的各种操作（加锁、释放、检查锁状态）都有系统开销，行锁的开销大于表锁。

总结：平衡**并发度**和**开销**。

### 锁类型

#### 读写锁

读锁（S）= 共享锁、写锁（X）= 互斥锁

两者的兼容关系如下：

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207213523777.png)

#### 意向锁

意向锁可以更容易地支持多粒度封锁。

原因：若没有该锁，如果事务T想对表A加锁，就要检查是否有其他事务已对**表A加锁**或**表A某一行**加锁，如果去一行行检测是很耗时的，所以引入意向锁，可以表示表A是否被**加行锁**。

意向锁是**表锁**，IS/IX之间互相兼容，且不会和**行级的X/S锁**发生冲突，只和**表级的X/S锁**冲突。意向锁是在**添加行锁**前数据库会**自动添加**的，规定：

​		一个事务在对某行数据添加S锁前，必须先获得该表的IS锁或更强的锁；

​		对某行数据加X锁前，必须先获得IX锁。

兼容关系（**表级**）：

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207214442687.png)

- 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。

## 封锁协议

### 三级别封锁协议

#### 一级封锁协议

事务T修改数据A前先加X锁，T结束才释放锁。可以解决**丢失修改**问题。

#### 二级封锁协议

在一级封锁协议的基础上规定，读取数据A前必须加S锁，**读完**释放。因此，由于 事务T修改数据前加了X锁，事务T2就无法加S锁，也就无法读取数据。可以进一步解决**脏读**问题。

#### 三级封锁协议

在二的基础上规定，读取数据A前必须加S锁，**事务结束**才释放。事务T再两次读取数据A中间，事务T2不能对数据A加X锁，这样事务T两次读取结果相同。可以进一步解决**不可重复读**。

### 两段锁协议

指每个事务的执行 可以分为加锁、解锁两个阶段，要求：

1、在对任何数据进行读、写操作前，要申请对该数据的封锁

2、所有封锁请求先于解锁请求。

若所有事务遵循该协议，则对这些事务的任何并发调度都是可串行化的，**不会出现一致性问题**。

注意：该协议是保证可串行化调度的**充分非必要**条件，即有的操作不满足该协议也能是可串行化调度。

## MySQL隐式和显式锁定

MySQL的InnoDB引擎采用**两段锁协议**

### 隐式

根据隔离级别在需要的时候自动加锁，并在同一时刻被释放。

### 显示

select ... lock in share mode;读锁

select ... for update;写锁

## 隔离级别

### 读未提交

事务的修改，即使未提交，也会被其他事务看到。

### 读已提交

事务的修改在提交前不会被其他事务看到。

### 可重复读

保证同一个事务中多次读取同一数据的结果相同。

### 串行化

强制事务串行执行，不会出现一致性问题。 **该隔离级别需要加锁**实现，保证同一时间只有一个事务执行。

## MVCC（InnoDB引擎独有）

是MySQL的**InnoDB**实现隔离级别的具体方式，实现**读已提交**和**可重复读**两个隔离级别。未提交读不需要使用MVCC，直接读取最新的数据行就完事了，而可串行化无法用MVCC实现，必须通过加锁，对所有读取的数据行加锁。

### 基本思想

封锁可以解决一致性问题，但实际场景中读操作多于写操作，于是引入了读锁、写锁，读与读之间不互斥，**读与写互斥**。

MVCC采用**多版本**思想，读操作读旧版本快照，写操作更新最新的版本快照，**读与写没有互斥关系**。

MVCC中事务的**修改操作**会为数据行**新增**一个版本快照。

MVCC规定只能读取**已提交**的快照和**自身未提交**的快照，来解决**脏读和不可重复读**问题。

### 快照中的版本号

- 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。
- 事务版本号 TRX_ID ：事务开始时的系统版本号。

### 快照存储位置--Undo日志

Undo日志通过回滚指针把一个数据行的所有快照连接起来。

例如在 MySQL 创建一个表 t，包含主键 id 和一个字段 x。我们先插入一个数据行，然后对该数据行执行两次更新操作。

```sql
INSERT INTO t(id, x) VALUES(1, "a");
UPDATE t SET x="b" WHERE id=1;
UPDATE t SET x="c" WHERE id=1;
```

因为没有使用 `START TRANSACTION` 将上面的操作当成一个事务来执行，**根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行并提交**，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191208164808217.png)



INSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。

### 未提交的事务存放处--ReadView

MVCC维护了一个ReadView结构，包含未提交的事务列表TRX_IDs {TRX_ID_1, TRX_ID_2, ...}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX。


![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191208171445674.png)



在进行 **SELECT 操作**（对于快照中的数据，不需要加锁）时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：

- TRX_ID < TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。
- TRX_ID > TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。
- TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX，需要根据隔离级别再进行判断：
  - 提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。
  - 可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。

在**数据行快照不可使用**的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到旧的快照，再进行上面的判断。

### 快照读和当前读

#### 快照读

select是快照读，操作快照中的数据，默认不加锁。

可以**显式**地强制加锁（lock in share mode\for update）

#### 当前读

修改操作（update,delete,insert），要加锁，读取的是最新的数据。

#### update加的是什么锁？

加表锁；

如果where子句中用到唯一索引，加record lock；

普通索引，加next-key lock。（record lock + gap lock，锁定一个范围，包括记录本身）

## MVCC完全不用加锁吗？

只有select默认不加锁，修改操作还是要加锁的。

## MVCC采用什么加锁算法？

InnoDB引擎**默认**隔离级别**可重复读**，使用的是**Next-Key lock**锁算法（record lock + gap lock），因此可以**避免幻读**，达到了SQL标准的**可串行化**隔离级别。

### 加锁算法类别

#### record lock：锁单个记录

#### gap lock：锁范围，不包含记录本身

#### next-key lock：锁范围，包含记录

## 乐观锁和悲观锁的区别

### 乐观锁

每次拿数据时都认为别人不会对数据进行修改，所以不上锁，但还是会在更新的时候判断一下别人在此期间是否修改了数据。适用于**读多写少**的场景。

例如版本号机制和CAS算法。

#### 版本号机制

数据表中增加一个**版本号字段**，表示数据**被修改的次数**，每改一次+1。线程在读取数据时会同时会读取版本号字段，提交更新时会检查**之前读取到的版本号**是否与**当前版本号**相同，不相同则重试更新操作。

#### CAS

三个参数：V--需读写的内存值  A--进行比较的值  B--准备写入的新值，当V==A时，通过原子方式将值更新成B，否则自旋。

#### 缺点 

1、ABA问题。通过增加版本号来解决，比如AtomicStampedReference引用类型。

2、自旋时间长开销大，如果长时间不成功，开销很大。

### 悲观锁

每次拿数据时都认为别人会修改，所以会先上锁，使其他线程阻塞等待。适用于**读少写多**的场景。

例如数据库中的写锁、读锁。Java中的synchronized、ReentrantLock。

## 数据库三范式

范式是符合某一级别的**关系模式的集合**。符合范式，可以避免很多异常，如冗余数据、删除异常、插入异常等。

### 第一范式

属性不可再分

### 第二范式

每个非主属性完全函数依赖于键码

### 第三范式

在第二范式的基础上消除传递依赖

## 内连接、左连接、右连接

### 内连接

显示两表的公共部分内容

### 左连接

左表的记录全部显示，右表只会显示符合条件的记录，不符合的地方为null。

### 右连接

右表的记录全部显示，左表只会显示符合条件的记录，不符合的地方为null。

## union和union all的区别

Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；

Union All：对两个结果集进行并集操作，包括重复行，不进行排序；

## 索引

### MySQL索引使用的数据结构

#### 哈希索引

数据结构是哈希表，表中存储指向行数据的**指针**，对所有的索引列计算哈希码，定位到哈希表中相应位置，获取s数据。

优点：查询单条记录性能最好。

缺点：

​	1、只有**精确匹配所有列**的查询才有效。（A，B）两列都要 匹配到才行。

​	2、**不支持顺序查询**

​	3、只支持等值比较查询，=，in（）；**不支持范围**，如>

#### BTree索引

数据结构是B+树，MyISAM和InnoDB实现该索引有区别，前者是非聚簇索引、后者是聚簇索引。

优点：

​	1、支持范围查询

​	2、查询性能稳定（都是从根到叶子）

​	3、在某些情况下（比如聚簇索引、覆盖索引）可以只通过索引完成查询，不需要回表。

缺点：查询单条记录性能不如哈希索引。

### 聚簇和非聚簇区别

#### 非聚簇索引

其索引结构和数据**分开存放**。叶子节点的data域中存放数据的地址，根据key找到数据地址后，需要根据地址去读取相应的数据记录。**辅助索引属于非聚簇索引**。

优点：更新代价较小，因为叶子节点不存放数据

缺点：需要回表（除非是**覆盖索引**！！！）

#### 聚簇索引

其索引结构和数据**一起存放**。叶子节点的**data域中存放完整的数据记录**，**key是主键**（没有主键则用**唯一索引**作主键，再没有则**生成rowid**作主键）。 InnoDB其他索引都作为辅助索引，data域存放主键值；使用辅助索引查找时，先找到主键值，再走主键索引，找数据记录。**主键索引属于聚簇索引**。

优点：查询快，不需要回表

缺点：如果索引无序插入的，会引起页分裂，降低性能；更新代价大，因为叶子节点存放数据。

### 覆盖索引

一个索引包含所有需要查询的字段的值，该索引就是覆盖索引。

例如，现在建立了**联合索引**（username，age）

```sql
select username , age from user where username = 'Java' and age = 22
```

在查询数据的时候：要查询出的列在叶子节点都存在！所以，就不用回表，故查询速度很快。

### 联合索引

可以以一定顺序引用多列的索引，即联合索引。

若有联合索引（a,b,c)，其中a是范围查询，则b，c列上的索引不会被用到。

注意：要将区分度高的字段放前面，即去重之后个数多的。

### 最左前缀原则

指的是，查询的时候如果精确匹配联合索引的前导列，则这些列能被用到。

### 唯一索引*vs*普通索引

唯一索引列不能重复出现相同的值，但允许null重复出现；主键不能重复、不能为null；普通能重复、能为null。

查询时：

对于唯一索引：查找到第一个满足条件的记录后就结束

对于普通索引，查找到第一个满足条件的记录后会继续查找，直到不满足条件。

更新时：

（普通可以使用change buffer，缓存更新操作，当下次查询到此数据页时才将更新操作落实。）

对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；

对于普通索引来说，则是将更新记录在**change buffer**，语句执行就结束了，当下次查询到此数据页时才将更新操作落实。

PS：在mysql 的innodb引擎中，是允许在**唯一索引**的字段中出现多个null值的。

### like % 会使用到索引吗？

like test% 

1.优先使用到范围查询, type为range

2.会使用到索引  using index

like %test

在**查询字段**都是**索引字段**时，会使用到索引(using where;using index)，type为index,对索引进行全扫描。

否则,不会使用索引（using where），会进行全表扫描，type为ALL。

### 索引失效的情况

1、隐式转换导致失效，即字符串字段为数字时，在where条件里不添加引号

2、对索引列使用内部函数

3、对索引列进行运算，以及使用<>，not in, not exist, !=等 ，大于小于这种，如果全盘扫描速度比索引速度快则不走索引 。

 还包括模糊查询%在前；

### 适合与不适合使用索引的情况

#### 适合创建索引的字段

不为null的

被频繁查询的

被作为条件查询的

被频繁用于连接的字段

#### 不适合创建索引的情况

被频繁更新的字段

不被经常查询的字段

就算创建索引也不会用到的情况

数据区分度小的字段（比如性别）。如果以重复值较高的字段作为查询条件，那么最终查出来的结果也会很多，使用索引的话会在普通索引和聚簇索引之间切换，那还不如直接全表扫描来得快，省去加载索引和回表查询。

数据量少的字段

### B树和B+树区别

|                    | B树                                          | B+树                                                         |
| ------------------ | -------------------------------------------- | ------------------------------------------------------------ |
| 每个结点关键字个数 | [m/2-1,m-1]  /向上取整                       | [m/2,m]  /向上取整                                           |
| 每个结点的子树个数 | 结点中n个关键字，n+1棵子树                   | 结点中n个关键字，n棵子树                                     |
| 结点存放信息       | 每个结点data域存放数据信息，叶节点不存放信息 | 非叶结点仅起索引作用，每个索引项含有对应子树的最大关键字和指向该子树的指针；叶结点data域存放数据信息，且形成有序链表 |
| 叶节点             | 关键字不重复                                 | 叶节点包含所有关键字                                         |

B+树的优势：

　　1.单一节点存储更多的元素，相同的数据量，B+树更加矮胖，使得查询的IO次数更少；
　　2.所有查询都要查找到叶子节点，查询性能稳定；
　　3.所有叶子节点形成有序链表，便于范围查询。

### 为啥用B+不用红黑树作索引？

这和索引的存储原理相关，页是InnoDB引擎管理数据库的最小磁盘单位（16KB），红黑树中一个父节点只有两个子节点，不能填满一个页上的内容，造成空间浪费，而B+树分支多，**不浪费空间**。而且，相同数量的内容，**B+树更矮，代表磁盘IO次数更少**，一次 IO耗时是毫秒级的。

所以红黑树和二叉树一般用在内存中，通常内存是纳秒级的。

## MyISAM和Innodb区别

|                        | MyISAM | InnoDB         |
| ---------------------- | ------ | -------------- |
| 锁                     | 表级锁 | 表级锁和行级锁 |
| 事务、崩溃后的数据恢复 | 不支持 | 支持           |
| 外键                   | 不支持 | 支持           |
| MVCC                   | 不支持 | 支持           |
| 索引                   | 非聚簇 | 聚簇           |

## 数据库大表优化

### 限定数据的范围

查询语句必须要带限制数据范围的条件

### 读写分离

**主从复制**是与之密切相关的技术。

主库写，从库读。

能提高性能的原因：1、极大缓解了锁的竞争；2、从服务器可以用MyISAM引擎，提升查询性能。

读写分离常用**代理方式**实现，代理服务器接收应用层发来的请求，决定转发到主服务器or从服务器。

### （主从复制--读写分离的基础）

与主从复制相关的线程有三个：binlog线程、I/O线程、SQL线程。

binlog线程：负责将主服务器上的数据更改 写进**二进制日志**（binary log）

I/O线程：负责从**主**服务器上**读取二进制日志**，写入**从**服务器的**中继日志**(relay log)

SQL线程：**读取中继日志**，解析出主服务器已经执行的数据更改，并**在从服务器replay**。

后两者是属于从服务器的线程。

### 垂直切分

数据表层面，将数据表按列分成多个表，可按**列的关系密集程度**or**使用是否频繁**进行切分。

数据库层面，按数据库中表的关系密集程度，部署到不用的库中。

优点：使每条数据记录的数据量变小，结点中可以存储更多条数据，减少查询时需要读取的结点数，进而减少IO次数。

缺点：主键出现冗余，并会引起join操作；让事务变得复杂。

### 水平切分

将数据表按行分成多个表。

优点：解决单一数据表量过大的问题，但数据终究在一个机器上，所以可以采用**水平分库提高并发能力**。

缺点：事务难处理。

### 分片两种常见方案

1、客户端代理

分片逻辑在应用端

2、中间件代理

在应用和数据之间添加代理层。分片逻辑在中间件维护。

### 分片（包括分库分表）后，id主键如何处理

1、snowflake算法

2、美团的leaf分布式ID生成系统





## **外键**

用来建立主表与从表的关联关系，为两个表的数据建立连接，约束两个表中数据的一致性和完整性。**一个表中的外键是另一个表中的主键**。

## 主键

1.一个表有且仅有一个

2.唯一性原则，唯一标识每一行，不能为null。

3.复合主键列表中不能重复出现同一列名

4.最小化原则，不包含多余列。







## explain各字段

![这里写图片描述](https://img-blog.csdn.net/20180520151002824?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3doeTE1NzMyNjI1OTk4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### **id：**select查询的序列号

id相同，从上向下顺序执行；不同，id大的优先。

### **select_type：表示查询的类型**

simple -- 说明查询中不包括子查询或union

primary -- 查询中包含复杂子部分，那么最外层查询标记为primary

subquery -- 说明**select/where** 列表中包含子查询

derived -- **from**列表中的子查询被标记成derived

union -- 出现在union后的select被标记为union

union result -- 从union表中获取结果的select语句

### **table：当前执行的表**

### **type：数据库引擎查找表的方式**

性能从优到劣：

system: 表中只有一行记录

const：通过索引**一次命中**，primary key/unique上的等值查询（select * from t where id = 1），**只匹配一行**数据。

eq_ref: 用于PK/unique，**唯一性**索引扫描，等值匹配，**每个索引键**只有**一条**匹配记录。

ref:**非唯一性**索引扫描，等值匹配，**每个索引键**有**多条**匹配记录

range：**索引上**的范围扫描，between / in / > / < 

index：**索引上**的全扫描，InnoDB的count

ALL：全表扫描

### **possible_keys:可能用到的索引**

### **key：实际用到的**

​	若查询中用到**覆盖索引**，索引仅出现在key中，possible_keys为空。

​	key为null说明没有建立索引或索引失效

### **key_len：索引字段的最大可能长度**

![image-20200830110328493](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200830110328493.png)

### **ref：显示索引的哪一列被使用了**

### **rows：找到所需记录所需要读取的大致行数**

### **extra：额外信息**

​	using filesort：表示在索引之外，需要额外进行外部的排序动作。

​	using temporary：使用临时表保存中间结果，常见于order by和group by

​	using join buffer：使用了连接缓存

​	impossible where：where子句总是false

​	select tables optimized away：基于索引优化MIN/MAX,COUNT(*)操作

​	distinct：优化distinct操作，找到第一个匹配的元组后停止

​	**using index**： 使用到**覆盖索引**，避免访问表的数据行，where筛选条件是索引的前导列（**索引条件查询**）。

​	**using index；using where**：使用到**覆盖索引**，where筛选条件是索引列之一但不是前导列（**无索引条件**）or是前导列的一个范围（**范围索引查询**），意味着**无法直接通过索引查找**到符合条件的数据（ref会显示为null）。

​	**using index condition**：查询列**未被索引覆盖**，需要回表查询数据，where中的条件是前导列的一个范围（**范围索引查询**）

​	**using where**：查询列**未被索引覆盖**，where筛选条件非索引前导列或非索引列（**无索引条件**）或者**范围索引查询**或者**索引条件查询+非索引条件**。

​	**null**:查询列**未被索引覆盖**，where条件是索引的前导列（**索引条件查询**）

<img src="https://upload-images.jianshu.io/upload_images/10040083-5dc40633e03a31c7.png" alt="img" style="zoom: 200%;" />

​	PS：根据上图记忆。

## in和exist区别

### in

确定给定的值是否与子查询或列表中的值相匹配。

有子查询的情况下：in在查询的时候，首先查询子查询的表，然后将内表和外表做一个笛卡尔积，然后按照条件进行筛选。所以相对内表比较小的时候，in的速度较快。

### exist

遍历循环外表，每次循环再对内表进行查询，看有没有匹配的。

总结：如果**子查询结果集记录较少**，**主查询中的表较大**且又有索引时应该用in, 反之如果外层的**主查询记录较少**，**子查询中的表大**，又有索引时使用exists。

## MySQL的结构

### server层

连接器：用户登录、身份认证

查询缓存：缓存select语句的执行结果，MYSQL8.0之后删除了缓存的功能，因为应用场景比较少，

分析器：1、词法分析，提取关键字、要查询的表、字段名、查询条件等 2、语法分析，判断语句语法是否正确

优化器：选择他认为最优的执行方案

执行器：校验权限后调用引擎层的接口，返回接口执行结果。

binlog：归档，逻辑日志记录执行的sql语句，追加方式写到日志文件中

### 引擎层

redolog：用于crash-safe，物理日志记录数据页的修改，日志文件大小固定，循环写。

## SQL语句的执行过程

查询语句：权限校验 ->查询缓存（8.0后移除）->分析器->优化器->权限校验->执行器->引擎

更新语句：分析器->权限校验->执行器->引擎（调用引擎层接口写入数据，保存在内存，同时记录redolog）->redo log 进入prepared状态，告知执行器->执行器记录binlog，再调用引擎层接口，提交redolog -> redo log commit 

### 为什么要两个日志？

起初MySQL的引擎是MyISAM，只有server层有binlog，起归档作用、用于主从同步和基于时间点的还原，不具备crash-safe能力，而InnoDB引擎有redolog，具备该能力。

### 两阶段提交（2PC）

第一阶段是调用引擎层接口写入数据，保存在内存，同时记录redolog，**redo log 进入prepared状态**，告知执行器。

第二阶段是执行器记录**binlog**，再调用引擎层接口，提交redolog，**redolog进入commit状态**。

这么做的原因：反证法解释。

​	**若先提交redolog，再写binlog。**写完redolog后挂了，binlog没写入，重启后用redolog恢复数据，但binlog没有记录该数据，造成数据不一致。

​	**若先写binlog，再写redolog。**写完binlog后异常重启，由于没有写入redolog，故redolog无法恢复该数据，造成数据不一致。

​	那么如果写完redolog、binlog后，遇到异常重启了，MySQL如何处理？

​	1、判断redolog是否完整，完整记录则redolog，进入prepared状态。

​	2、若已经是prepared状态，去判断binlog是否完整，完整就提交redolog，否则回滚。

​	redolog影响主库数据，binlog影响从库数据（因为binlog用于主从复制），两阶段提交能使redolog和binlog保持一致，从而保证主从数据一致。

### WAL（write ahead log）日志先行技术

不直接更改磁盘中的数据（因为直接写是随机写，开销大性能低），而是先在内存中更改，再写日志（用于断电重启后的恢复，是顺序写，开销较小），最后再落盘。



# Redis

## Redis数据类型和结构

| 数据类型 | 可以存储的值           | 操作                                                         |
| -------- | ---------------------- | ------------------------------------------------------------ |
| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作；对整数和浮点数执行自增或者自减操作 |
| LIST     | 列表                   | 从两端压入或者弹出元素；对单个或者多个元素进行修剪， 只保留一个范围内的元素 |
| SET      | 无序集合               | 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集 从集合里面随机获取元素 |
| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 |
| ZSET     | 有序集合               | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 |

### String类型的底层数据结构

使用simple dynamic string（简单动态字符串），**SDS**定义如下：

```C++
struct sdshdr{
   //记录buf数组中已使用字节的数量
   //等于 SDS 保存字符串的长度
   int len;
   //记录 buf 数组中未使用字节的数量
   int free;
   //字节数组，用于保存字符串
   char buf[];
}
```

使用SDS的好处：

​	1、获取字符串长度的时间复杂度是O(1)，直接通过读取len属性即可（strlen key）。而C语言中要通过遍历计数获取长度。

​	2、杜绝缓冲区溢出。要对SDS进行修改时，会先检查当前的空间大小是否满足需求，若不满足就进行扩容。

​	3、减少修改字符串时内存重分配的次数。内存重分配的作用是在**增长**字符串时**避免缓冲区溢出**，**减小**字符串时避免**内存泄漏**。SDS对于修改字符串，有**空间预分配**和**惰性空间释放**两策略。

​	空间预分配 ：进行空间扩展时，扩展的内存比实际需求多，以此减少连续增长字符串时所需的内存重分配次数。

​	惰性空间释放：进行字符串缩短操作时，不立即进行内存重分配来回收多余的字节，而用free属性记录这些字节数量。

### Hash类型的数据结构

采用**字典**，字典中包括两个散列表。

dictht是散列表 ，使用拉链法解决哈希冲突。

```C
/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
typedef struct dictht {
    dictEntry **table;//是一个数组
    unsigned long size;//哈希表的大小，即table数组的大小
    unsigned long sizemask;//sizemask = size - 1
    unsigned long used;//表中已有结点的数量
} dictht;
```

散列表节点

```c
typedef struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;
} dictEntry;
```

字典结构

```C
typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2];//两个散列表，为了方便进行rehash操作
    long rehashidx; /* rehashing not in progress if rehashidx == -1 ，否则代表正在rehash的元素的索引*/
    unsigned long iterators; /* number of iterators currently running */
} dict;
```

#### 什么时候进行rehash？

字典中有个负载因子=结点数量/数组长度，默认值为5，超过该值进行rehash。

#### 为何渐进式rehash

避免一次性执行过多的rehash给服务器造成很大负担。

#### 介绍一下渐进式rehash

1、为ht[1]分配空间，大小为第一个大于ht[0].used * 2的2的幂。

2、将rehashidx设为0，表示正式开始rehash

3、在进行rehash期间，每次对字典进行增、删、改、查操作时，程序除了执行这些操作，另外还要将ht[0].table中下标为rehashidx的位置上的所有键值对迁移到ht[1].table上，完成后rehashidx自增。为防止ht[0]是稀疏表，遍历很久遇到的都是NULL，从而导致阻塞时间过长，引入了**最大空格访问数**（empty_visits=n*10），当遇到的NULL数量超过这个值就直接返回。

4、当ht[0].used=0，说明所有键值对都迁移到ht[1]了，释放ht[0].table，交换ht[0]和ht[1]的角色，rehashidx标记为-1，代表rehash结束。

### ZSet类型的底层数据结构

是**跳表**（查询、插入、删除的时间复杂度为logN），基于多指针有序链表实现 。

查找时，从上层指针开始 ，找到对应的区间后再到下一层查找，类似二分查找，时间复杂度O（lgn）。

插入时，结点的层数随机生成，需要更改相邻结点的指针。

相比红黑树的优点（为什么使用跳表而不是红黑树？）：

1、插入、删除速度快，不需要旋转等操作来维护平衡，只需要修改相邻结点的指针。

2、范围查询时，操作要更简单，只需要找到小值后，对第一层链表进行遍历即可；而红黑树则要进行中序遍历，相比较复杂。

2、容易实现

3、支持无锁操作，实现插入操作时依靠CAS保证线程安全。 

## Redis支持事务吗？

支持。通过MULTI、EXEC、WATCH等命令实现事务功能。事务提供了将多个命令请求打包，然后一次性、顺序执行的机制，在事务执行完成前，不会中断转而去执行其他客户端的请求。

Redis中的事务具有一致性、隔离性、持久性、**没有原子性**。(虽然事务没有原子性，但redis操作有原子性)

PS:关于原子性，事务中若出现语法错误的指令，会显示错误，执行exec时失败，指令无一执行；**若出现语法正确，但逻辑错误的指令（比如给一个String自增），执行exec时会显示该条错误，其他指令成功执行**。

## Redis单线程/多线程

Redis4.0**之前**单线程，原因：

1、开发维护更简单，单线程方便开发和调试  

2、能够并发地处理多客户端的请求，采用基于epoll的多路复用。（**并发量高的原因**）

3、主要性能瓶颈是内存或网络带宽，非CPU

Redis4.0**及之后**引入惰性删除，可使用异步方式删除数据（unlink key, flushdb async, flushall async）。unlink key，unlink 命令在另一线程回收内存，所以是非阻塞的。而del会产生阻塞，造成主线程卡顿。

Redis6.0多线程，主线程串行执行redis命令，用一组独立线程执行IO读写任务，这样可以实现多个socket的读写 并行化。

## Redis为什么快？

1、采用多路IO复用机制（具体是采用epoll）

2、数据结构简单，操作节省时间（比如跳表）

3、运行在内存中

## Redis和Memcached区别

![image-20200901094031032](C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200901094031032.png)

虚拟内存机制在redis2.6后被移除，思想就是将内存中不使用的数据放到磁盘中。

## Redis持久化

### Redis持久化过程

1.客户端向redis发送写命令（数据在**客户端内存**）

2.redis执行命令（redis**服务器内存**）

3.redis调用**系统API**将数据写入**内核缓冲区**  **posix file API**  **write**指令

4.操作系统将**内核缓冲区**内容传给**磁盘控制器**（**磁盘缓冲区**） **posix API**中的**fsync**指令

5.磁盘控制器写入**实际的物理媒介**（**磁盘**）

### 持久化方式

#### RDB

快照持久化，在指定的时间间隔内将内存中的数据集快照写入磁盘，具体是会fork一个子进程，将数据集写入临时文件，写入成功后 ，替换之前的文件，用二进制压缩存储。

优点：

​	1、会生成多个数据文件，每个文件分别代表了某一时候redis里的数据，这样可以指定恢复到某时刻的数据。

​	2、数据恢复速度比AOF快

​	3、对Redis的性能影响小，因为同步数据时fork子进程去做持久化。

缺点：

​	若服务器宕机，采用RDB会造成某个时间段内的数据丢失，而AOF最多丢失1秒。

#### AOF

将每条写命令以追加的方式写入日志文件，配置文件中有三种方式：appendfsync always， appendfsync everysec； appendfsync no。为兼顾数据和redis性能，采用每秒同步一次的方式，将AOF缓冲区中的增删改相关指令写到磁盘文件中。（若AOF和RDB都开启了，Redis重启时默认使用AOF恢复数据，因为AOF更完整）

优点：

​	1、数据丢失少

​	2、以追加方式将命令写入文件，少了很多磁盘选址的开销，写入性能好。

缺点：

​	1、一样的数据，AOF文件比RDB大。

​	2、AOF支持的QPS更少，因为每秒异步刷新一次日志。

#### 两者如何选择？

都整上，两者能互补。RDB数据恢复快，AOF数据恢复完整，到时候第一时间 用RDB恢复，再用AOF做补全，保持Redis的高可用性。

### AOF文件重写

对应的命令是BGREWRITEAOF，父进程fork子进程，fork采用**COW技术**，子进程和父进程共享内存数据，子进程会基于使文件体积尽量小的规则，将目前与增删改相关的操作写入到一个新的AOF文件中。在这个过程中，父进程正常响应命令，把命令写入到AOF缓冲区，并按照appendfsync策略同步到硬盘，保证原有的aof机制的有效性。同时，会将命令写入到AOF重写缓冲区中，待子进程将新的AOF创建完成后，追加进去，最后用新的AOF文件替换旧AOF。

### 混合持久化

混合持久化同样也是通过`bgrewriteaof`完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本**全量**的以RDB方式写入aof文件，然后再将AOF重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。简单的说：**新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据。**

### **COW技术**

父进程fork（）子进程，就是创建一个跟父进程相同的子进程（pid不同，数据段、代码段、堆栈段相同），子进程会执行 fork（）函数之后的代码。

fork出来的子进程（pid不同，数据段、代码段、堆栈段相同）共享父进程的内存空间，当父子进程对内存空间有写入操作时，会触发页异常中断，复制该内存页给子进程。一般写入操作发生在数据段、堆栈段，代码段继续共享父进程内存空间。但是！若用exec函数，会为子进程代码段分配单独的空间。



## 缓存穿透 、击穿、雪崩

**缓存穿透**：查询的key不存在与缓存和数据库中，所以每次请求都会到达数据库

解决方案：采用布隆过滤器、缓存无效的key（设置过期时间）

**缓存击穿**：指一个热点key，扛着大并发，在失效瞬间，大量请求直接到达数据库。

解决方案：使用互斥锁。写一个get缓存的方法，该方法中，当缓存失效，不立即去请求数据库，而是用SETNX指令去set一个mutex key，当操作返回成功时，再去请求数据库并回设缓存；否则，重试整个get缓存的方法。

**缓存雪崩**：缓存同一时间大面积失效，请求落到数据库上，导致数据库短时间承受大量请求而崩溃。

解决方案：

​	事前：保证redis集群的高可用性（主从复制+哨兵），选择合适的内存淘汰策略。

​	事中：本地ehcache缓存+ hystrix限流&降级，避免MySQL崩掉

​	事后：利用redis持久化机制保存的数据恢复缓存 

## Redis设置过期时间

为键设置过期时间，redis会通过**定期删除**和**惰性删除**两种方式删除过期的键。

定期删除：默认每隔100ms随机抽取一些设置了过期时间的key进行删除

惰性删除：查看key发现过期才删除。

光靠这两种删除方法，不能避免内存满的情况，所有需要设置内存淘汰机制。

## 设置内存淘汰机制

一种有8种，

对于已设置过期时间的数据：volatile-lru，volatile-lfu，volatile-random，volatile-ttl，

其他：allkeys-lru，allkeys-lfu，allkeys-random，no-eviction

## Redis主从复制

全量同步，发生在从服务器初始化阶段，过程：

0、从服务器连接主服务器，发送SYNC命令。

1、主服务器创建RDB文件并发送给从服务器，同时 在发送期间使用缓冲区记录执行的写命令。待RDB文件发送完后，发送缓冲区中的写命令。

2、从服务器丢弃旧数据，载入主服务器发来的RDB文件和写命令。

增量同步：

​	从服务器初始化后，主服务器每执行一次写命令，都发给从服务器，从服务器接受并执行。

## Redis哨兵模式

### 哨兵进程的作用

1、**监控(Monitoring):** 哨兵(sentinel) 会不断地检查你的Master和Slave是否运作正常。

2、**提醒(Notification)**:当监控的某个Redis节点出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知。

3、**自动故障迁移(Automatic failover)**：当**一个Master不能正常工作**时（客观下线），哨兵(sentinel) 会将其转移到Slave上。

4、**配置**：故障转移发生后，通知client客户端新的master地址。

### 哨兵进程的工作方式

首先介绍两个指令，

PING命令作用：心跳检测，是失败判定的依据。

INFO作用：a）发现slave节点   b）确认主从关系

1.每个Sentinel（哨兵）进程以**每秒钟一次**的频率向整个集群中的**Master主服务器，Slave从服务器以及其他Sentinel**（哨兵）进程发送一个 **PING 命令**。

2.如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel（哨兵）进程标记为**主观下线（SDOWN）**。

3.如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有
Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态。

4.当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值，一般是半数）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为**客观下线**（ODOWN），之后哨兵进行**自动故障迁移**。

5.若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除.

6.在一般情况下， 每个Sentinel（哨兵）进程会以**每 10 秒一次**的频率向集群中的所有Master主服务器、Slave从服务器发送 **INFO 命令**。

7.当Master主服务器被 Sentinel（哨兵）进程**标记为客观下线（ODOWN）时**，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 **INFO 命令**的频率会从 10 秒一次改为**每秒一次**。



Master被标记为**ODOWN**之后哨兵进行**automatic failover**自动故障迁移：

1、它会将失效Master的其中一个Slave升级为新的Master, 并让失效Master的其他Slave改为复制新的Master；

2、当客户端试图连接失效的Master时，集群也会向客户端返回新Master的地址，使得集群可以使用现在的Master替换失效Master。

3、Master和Slave服务器切换后，Master的redis.conf、Slave的redis.conf和sentinel.conf的配置文件的内容都会发生相应的改变，即，Master主服务器的redis.conf配置文件中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换。

## Redis的分片

分片：将数据进行划分并存储到多台机器里。

假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。

- 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。
- 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。

  优势：redis实例相互独立，容易进行线性扩展，系统灵活性强。

  劣势：1、由于分片放在客户端，规模扩大时运维难度大。

  ​			2、Redis实例群拓扑结构变化时，每个客户端都要更新调整。

- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。

- 服务器分片：Redis Cluster。

  优势：客户端像使用单Redis服务器一样使用Redis集群，运维管理方便。

  劣势：性能不太行。

### Redis Cluster

Redis Cluster中采用slot（槽）的思想，共分成16834个槽。对于每个进入Redis的键值对，对key进行散列，分配到槽中。使用的hash算法是，CRC16后对16834取模。

每个slot都有对应的node（redis集群中的结点）负责处理，当动态增减node节点时，会对slot进行重分配，且slot中的键值也要迁移。

为了保证高可用，将node配置成主从结构，即一个master节点，多个slave节点。主节点失效，redis cluster根据选举算法选一个slave替上，注意这里不是用的哨兵机制，而是cluster自带的故障转移容错能力。

Redis cluster的新节点识别能力、故障判断及转移能力是通过集群中的每个node间的通信实现的，这叫**集群总线**。

对客户端来说，整个cluster被看成是一个整体，客户端可以连接任意node，若key不在此node上，redis会返回转向指令，指向正确的node。

### Redis sharding集群

在Redis cluster出来前的普遍使用的多Redis实例集群方法。

主要思想：采用一致性哈希算法将key散列到特定redis节点上。

#### hash算法的弊端

将redis节点数量发生变化时，数据缓存的位置会变化。因为hash算法的计算方式是将key的hash值对节点数量取余。解决方法：一致性hash算法

#### 一致性hash算法

一致性hash是由一个固定长度的hash环构成，长度大小为2^32。

在增加节点时，会根据节点名称的hash值，将服务器节点放置在该环上。添加数据或增删节点时，会计算key的hash值，顺时针方向寻找到离该值最近的服务器节点，完成key到服务器的映射。然而，这样仍**存在节点负载不均衡的问题**。故引入虚拟节点。

##### 虚拟节点

给服务器节点增加副本，即虚拟节点。使负载更均衡。服务器多，需要的虚拟节点少；服务器少，需要的虚拟节点要多一些。

#### 一致性hash算法的好处

如果一台服务器不可用，那么只会对环中该服务器与前一服务器之间的数据造成影响，范围较小。

如果增加一台服务器，只有该服务器与前一服务器之间的数据受影响，一致性hash增强了系统鲁棒性。

但仍然会有部分数据丢失的风险。

### 使用代理中间件实现大规模redis集群

客户端通过代理中间件访问Redis服务器。中间件可以通过共享与后端系统的连接，降低客户端直接连接后端服务器的连接数量。



## 集群如何判断某个节点是否挂掉

首先，每个节点都有集群中其他主节点及从节点的信息，节点之间通过ping-pong判断是否可以连接上。若有一半以上的节点去ping一个节点的时候无回应，则认为该节点挂掉，会从该节点的slave中**选举**出一个master。

## 选举原理

当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下：
1.slave发现自己的master变为FAIL
2.将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息
3.其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack
4.尝试failover的slave收集FAILOVER_AUTH_ACK
5.超过半数后变成新Master
6.广播Pong通知其他集群节点。

## 集群什么时候进入fail状态（不工作状态）

1、某个主节点及其从节点全部挂掉

2、半数以上的主节点挂掉，无论是否有slave，都进入fail状态

3、某个主节点挂掉且其没有从节点

## Redis的双写一致性

先删除缓存再更新数据库、延时双删、读请求和写请求串行化。 

## 如何解决Redis的并发竞争key的问题？用分布式锁

使用Redis的SETNX、GET、GETSET指令。

1、SETNX设置锁，设置过期时间

2、用GET获取锁的获取时间 ，若发现已过期，使用GETSET指令设置新的过期时间

3、GETSET在设置新值时会返回旧值，若旧值仍然是过期的时间，说明正确地加锁了，否则，说明别的线程已经设置了锁，当前进程只更新了以下，所以继 

## 创建型模式之工厂模式

### **简单工厂模式**

一个工厂，生产多种类型产品。

<img src="C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200723162631050.png" alt="image-20200723162631050" style="zoom: 67%;" />

### **工厂方法模式**

抽象类工厂（一个接口）可有多个具体工厂实现类，每个工厂实现类只生产一种类型的产品。

<img src="C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200723162445222.png" alt="image-20200723162445222" style="zoom:67%;" />

### **抽象工厂模式**

抽象类工厂（多个接口）可有多个具体工厂实现类，每个工厂实现类能生产不同类型的产品。

<img src="C:\Users\Minyu Chen\AppData\Roaming\Typora\typora-user-images\image-20200723161900403.png" alt="image-20200723161900403" style="zoom:67%;" />



## [Spring中用到的模式](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485303&idx=1&sn=9e4626a1e3f001f9b0d84a6fa0cff04a&chksm=cea248bcf9d5c1aaf48b67cc52bac74eb29d6037848d6cf213b0e5466f2d1fda970db700ba41&token=255050878&lang=zh_CN#rd)

### **代理模式**



# Spring

## AOP代理对象什么时候生成？

所有的bean在返回给用户使用之前都需要经过AnnotationAwareAspectJAutoProxyCreator类的postProcessAfterInitialization()方法，而该方法的主要作用也就是将所有拥有advice的bean重新包装为proxy。

# Kafka

# RabbitMQ

# 分布式和大数据场景

## 分布式事务

一次大的操作由多个小操作组成，这些小操作分布在不同的服务器上，且属于不同的应用，分布式事务就是要保证这些小操作要么都成功，要么都失败。分布式事务的目的是为了保证不同数据库的数据一致性。

## CAP理论

CAP理论指出一个分布式计算系统不可能同时满足以下三点：

一致性consistency：同一时刻，分布式系统中所有节点的数据备份是相同的

可用性availability：在一部分节点故障后，集群仍能响应客户端请求

分区容错性partition tolerance：当分布式系统中因为一些原因导致无法通信而分为多个分区，系统还能正常对外服务

当发生网络分区时，如果要继续服务，一致性和可用性只能2选1。

## BASE理论

该理论包含下面三点：

基本可用Basically Available：指分布式系统出现不可预知的故障时，允许损失部分可用性。如，响应时间上的损失、系统功能上的损失。

软状态Soft-state：指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不用节点的数据副本之间进行数据同步的过程存在延时。

最终一致性Eventually consistent：指经过一段时间的同步后，系统中的数据副本最终能达到一致的状态。



BASE是对CAP中一致性和可用性权衡的结果，核心思想：

即使无法达到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方式使系统达到最终一致性。

## 分布式ID

分布式ID就是全局唯一ID。当数据量很大时，需要进行分库分表，就需要一个全局唯一ID来标识数据。

### 分布式ID需要满足的条件

1、全局唯一性

2、高性能：高可用低时延地生成ID。

3、容易接入：秉持拿来即用的设计原则。

4、最好是递增的，尤其作为索引字段的时候。

### 生成分布式ID的方法

1、UUID

```java
String uuid = UUID.randomUUID().toString().replaceAll("-","");
```

​	优点：生成简单，本地生成，无网络消耗

​	缺点：没有具体的业务含义、过长导致查询存储效率低、无序导致数据位置频繁变动

2、数据库自增ID

基于数据库的auto_increment自增ID可以充当分布式ID。

​	优点：简单、递增

​	缺点：DB单点存在宕机风险，无法抗住高并发

3、基于数据库集群模式的自增ID

是对2的改进，将单DB改成主从模式集群且是双主模型集群。两个mysql实例都能独自生成自增ID。

为避免生成重复ID，需要各自设置**起始值**和**自增步长**。

如果两个实例仍然扛不住高并发，则新增实例，同时要修改旧实例的起始值和步长。

​	优点：解决DB单点问题

​	缺点：不利于后续扩容，单数据库压力依然大，无法满足高并发场景。

4、基于数据库的号段模式

号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将使用本号段，生成相应范围的自增ID并加载到内存。表结构如下：

```java
CREATE TABLE id_generator (
  id int(10) NOT NULL,
  max_id bigint(20) NOT NULL COMMENT '当前最大id',
  step int(20) NOT NULL COMMENT '号段的布长',
  biz_type	int(20) NOT NULL COMMENT '业务类型',
  version int(20) NOT NULL COMMENT '版本号',
  PRIMARY KEY (`id`)
) 
```

biz_type ：代表不同业务类型

max_id ：当前最大的可用id

step ：代表号段的长度

version ：是一个乐观锁，每次都更新version，保证并发时数据的正确性

![img](https://pic3.zhimg.com/80/v2-abc2633c6ff85daf95fca018f717a24e_720w.png)

等这批号段ID用完，再次向数据库申请新号段，对`max_id`字段做一次`update`操作，`update max_id = max_id + step`，update成功则说明新号段获取成功，新的号段范围是`(max_id ,max_id +step]`。

```java
update id_generator set max_id = #{max_id+step}, version = version + 1 where version = # {version} and biz_type = XXX
```

由于多业务端可能同时操作，所以采用版本号`version`乐观锁方式更新，这种`分布式ID`生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。

5、Redis

利用`redis`的 `incr`命令实现ID的原子性自增。

用`redis`实现需要注意一点，要考虑到redis持久化的问题。`redis`有两种持久化方式`RDB`和`AOF`

- `RDB`会定时打一个快照进行持久化，假如连续自增但`redis`没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。
- `AOF`会对每条写命令进行持久化，即使`Redis`挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致`Redis`重启恢复的数据时间过长。

6、雪花算法

![img](https://pic2.zhimg.com/80/v2-4f51c7b6704323cc376b5a8a9a7cad09_720w.jpg)

`Snowflake`生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。

- 第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。
- 时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69年
- 工作机器id（10bit）：也被叫做`workId`，这个可以灵活配置，机房或者机器号组合都可以。
- 序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID

7、美团leaf

`Leaf`同时支持号段模式和`snowflake`算法模式，可以切换使用。

**号段模式**

先导入源码 [github.com/Meituan-Dia…](https://link.zhihu.com/?target=https%3A//github.com/Meituan-Dianping/Leaf) ，在建一张表`leaf_alloc`

```java
DROP TABLE IF EXISTS `leaf_alloc`;

CREATE TABLE `leaf_alloc` (
  `biz_tag` varchar(128)  NOT NULL DEFAULT '' COMMENT '业务key',
  `max_id` bigint(20) NOT NULL DEFAULT '1' COMMENT '当前已经分配了的最大id',
  `step` int(11) NOT NULL COMMENT '初始步长，也是动态调整的最小步长',
  `description` varchar(256)  DEFAULT NULL COMMENT '业务key的描述',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '数据库维护的更新时间',
  PRIMARY KEY (`biz_tag`)
) ENGINE=InnoDB;
```

然后在项目中开启`号段模式`，配置对应的数据库信息，并关闭`snowflake`模式

```java
leaf.name=com.sankuai.leaf.opensource.test
leaf.segment.enable=true
leaf.jdbc.url=jdbc:mysql://localhost:3306/leaf_test?useUnicode=true&characterEncoding=utf8&characterSetResults=utf8
leaf.jdbc.username=root
leaf.jdbc.password=root

leaf.snowflake.enable=false
#leaf.snowflake.zk.address=
#leaf.snowflake.port=
```

启动`leaf-server` 模块的 `LeafServerApplication`项目就跑起来了

**snowflake模式**

`Leaf`的snowflake模式依赖于`ZooKeeper`，不同于`原始snowflake`算法之处是在`workId`的生成上，`Leaf`中`workId`是基于`ZooKeeper`的顺序Id来生成的，每个应用在使用`Leaf-snowflake`时，启动时都会都在`Zookeeper`中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个`workId`。

## 分布式协议（一致性协议）

### Paxos

### RAFT

http://ifeve.com/raft/

## URL黑名单问题：判断值是否已经存在于集合中

使用**布隆过滤器**，该过滤器由二进制向量和多个哈希函数组成。

哈希函数算出的Integer的范围在0-2^32-1，那么可以定义一个长度为2^32-1的bit数组（java中可以用byte数组实现），这个数组空间占用为512M。根据哈希值的二进制形式，将bit数组中相应位置的值设置为1。判断的时候，计算出哈希值，看其在数组中相应位置上的值是否为1，是的话，可能存在(因为存在hash碰撞，不同的URL，哈希值相同)，否则一定不存在。

为减少误判概率，使用不同的哈希函数得到不同的哈希值并落实到数组上。

## 如何只用2GB内存从20/40/80亿个int整数中找到出现次数最多的数

https://blog.csdn.net/WantFlyDaCheng/article/details/100078613?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

## 40亿个非负整数没出现的数

要求这里的非负整数是32位也就是0~2^32-1。最多用1GB的内存。如果只能用10MB的空间呢，只需要找到一个没有出现的数即可。

首先先分析一下，40亿个4B约为16GB这里只用1GB，这里要求注意是找出没出现，这就和网页过滤系统类似，出现与不出现两个状态（0和1），那么我们就可以用bit数组来确定。我们用一个长度为2^32的bit数组，内存大小为2^29B为512MB不到一个GB。bit数组下标对应非负整数。数组值表示是否出现。遍历2遍。第一遍根据40亿个数填充bit数组，第二遍根据数组为0的找出没有出现的数。

对于第二个要求的话，只有10MB的空间，那么我们只将512MB的数组
分到只剩不到10MB，那么将0~2^32-1的范围分成64份，则bit数组将只用8MB。再用一个长度为64的int类型数组来记录每一份的数字个数，这64个数中肯定有小于2^26的，找到这个数字段，在创建一个长度为2^26bit数组，遍历40亿的数，只关心在备选范围里数据，填充数组，遍历数组，发现一个未出现的数。

## 找到100亿个URL中重复的URL

https://www.nowcoder.com/discuss/32190?type=0&order=0&pos=16&page=1

## 40亿个非负整数中找到出现两次的数和所有数的中位数

### 找出现两次的数

对于在很多整数中找出现次数的题，一般是使用哈希表对出现的每一个数做词频统计的。但是这个题只需要找出现2次的整数，如果还使用哈希表 key表示出现的数，value表示出现的数的次数，那么这样需要的内存空间更大，而且对于出现次数大于2次的数没必要再去统计，所以哈希表在此处有点不太合适。那么应该怎么计算呢，我们先计算一下，如果每一个数用2位来做词频统计，那么就包括了0次是00,1次是01，2次是10,3次是11，这样就足够了，也省下不少空间，一个数2位，40亿个数就是80亿位，也就是10亿字节，那么就需要大概1GB的空间来处理，刚好满足条件。

具体计算步骤如下：

1、申请开辟一个长度为4294967295*2的bit数组，即bitArray[4294967295*2]，占用内存空间约为1GB。

2、用bitArray数组的每2个位置表示一个出现的词频，遍历40亿个数，记为num，如果第一次出现num，则把

　　bitArray[num*2]和bitArray[num*2+1]置为01，num第二次出现就把bitArray[num*2]和bitArray[num*2+1]设

　　置为10，第三次出现就设置为11，如果大于3次出现则忽略不管，仍然保持11状态。

3、遍历bitArray数组，如果发现bitArray[i*2]和bitArray[i*2+1]的值是10，那么i就是出现了两次的数。

### 找中位数

还是先根据内存划分最大可用区间的大小，然后遍历所有数统计每个区间的个数，根据这个数确定中位数具体落到哪一个区间上，然后再次遍历所有数只关注落到此区间数的计数值，然后就可以找到中位数是哪一个了。